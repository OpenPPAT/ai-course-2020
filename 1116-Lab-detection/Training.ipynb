{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Declare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<class 'data.subt_artifact.SUBTDetection'>\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = \"/home/austin/DataSet/ncsist_dataset/ncsist\"\n",
    "DATASET_NAME = \"ncsisT\"\n",
    "cfg = subt\n",
    "BASE_NET = \"./weights/vgg16_reducedfc.pth\"\n",
    "DATA_DETECTION = SUBTDetection\n",
    "BATCH_SIZE = 2\n",
    "PRETRAINED_MODEL = None\n",
    "PRETRAINED_ITER = 0\n",
    "SAVE_MODEL_ITER = 500\n",
    "START_ITER = 0\n",
    "NUM_WORKERS = 4\n",
    "CUDA = True\n",
    "LR = 1e-3\n",
    "MOMENTUM = 0.4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "GAMMA = 0.1\n",
    "VISDOM = False\n",
    "SAVE_FOLDER = \"./weights/\" + DATASET_NAME + \"/\"\n",
    "if not os.path.exists(SAVE_FOLDER):\n",
    "    os.makedirs(SAVE_FOLDER)\n",
    "print('done')\n",
    "print(DATA_DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if not CUDA:\n",
    "        print(\"WTF are u wasting your CUDA device?\")\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "# Initial model weights & bias\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "# Adjust learning rate during training\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = LR * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        print(\"Change learning rate to: \", lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to index: \n",
      " {'missle': 0, 'backpack': 1, 'blueline': 2, 'drill': 3, 'can': 4}\n",
      "['missle', 'backpack', 'blueline', 'drill', 'can', 'None']\n",
      "<data.subt_artifact.SUBTAnnotationTransform object at 0x7f52086d2e10>\n"
     ]
    }
   ],
   "source": [
    "dataset = DATA_DETECTION(root=DATASET_ROOT, image_sets=['train'],transform=SSDAugmentation(cfg['min_dim'], MEANS))\n",
    "\n",
    "classes = dataset.target_transform.class_to_ind\n",
    "print(\"Class to index: \\n\", classes)\n",
    "classes = sorted(classes.items(), key=lambda kv: kv[1])\n",
    "label = []\n",
    "for i in classes:\n",
    "    label.append(i[0])\n",
    "label.append('None')\n",
    "print(label)\n",
    "true_label = ['missle', 'backpack', 'blueline', 'drill', 'can']\n",
    "print(dataset.target_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing weights...\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/ssd.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "/home/austin/SSD-SubT/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Delcare SSD Network\n",
    "#ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])\n",
    "ssd_net = build_ssd('train', cfg['min_dim'], 6)\n",
    "net = ssd_net\n",
    "if CUDA:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "if PRETRAINED_MODEL is not None: # Use SSD pretrained model\n",
    "    print('Resuming training, loading {}...'.format(PRETRAINED_MODEL))\n",
    "    ssd_net.load_weights(SAVE_FOLDER + PRETRAINED_MODEL)\n",
    "else:\n",
    "    print('Initializing weights...')\n",
    "    vgg_weights = torch.load(BASE_NET) # load vgg pretrained model\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "    ssd_net.extras.apply(weights_init) # Initial SSD model weights & bias\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM,\n",
    "                weight_decay=WEIGHT_DECAY)\n",
    "print(cfg['min_dim'])\n",
    "#criterion = MultiBoxLoss(BATCH_SIZE ,cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,\n",
    "                #False, CUDA)\n",
    "criterion = MultiBoxLoss(BATCH_SIZE ,6, 0.5, True, 0, True, 3, 0.5,False, CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Training SSD on: ncsisT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "# loss counters\n",
    "loc_loss = 0\n",
    "conf_loss = 0\n",
    "epoch = 0\n",
    "print('Loading the dataset...')\n",
    "epoch_size = len(dataset) // BATCH_SIZE\n",
    "print('Training SSD on:', DATASET_NAME)\n",
    "\n",
    "data_loader = data.DataLoader(dataset, BATCH_SIZE,\n",
    "                                num_workers=NUM_WORKERS,\n",
    "                                shuffle=True, collate_fn=detection_collate,\n",
    "                                pin_memory=True)\n",
    "batch_iterator = iter(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n",
      "/home/austin/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 1.7200 sec.\n",
      "iter 0 || Loss: 28.6628 ||timer: 0.0752 sec.\n",
      "iter 10 || Loss: 19.1131 ||timer: 0.0747 sec.\n",
      "iter 20 || Loss: 19.0386 ||timer: 0.0765 sec.\n",
      "iter 30 || Loss: 13.4547 ||timer: 0.0748 sec.\n",
      "iter 40 || Loss: 15.8399 ||timer: 0.0752 sec.\n",
      "iter 50 || Loss: 37.9447 ||timer: 0.0748 sec.\n",
      "iter 60 || Loss: 21.6317 ||timer: 0.0751 sec.\n",
      "iter 70 || Loss: 13.3289 ||timer: 0.0755 sec.\n",
      "iter 80 || Loss: 25.9155 ||timer: 0.0751 sec.\n",
      "iter 90 || Loss: 16.0891 ||timer: 0.0746 sec.\n",
      "iter 100 || Loss: 41.9437 ||timer: 0.0750 sec.\n",
      "iter 110 || Loss: 14.9400 ||timer: 0.0754 sec.\n",
      "iter 120 || Loss: 18.1226 ||timer: 0.0756 sec.\n",
      "iter 130 || Loss: 25.3969 ||timer: 0.0753 sec.\n",
      "iter 140 || Loss: 14.3746 ||timer: 0.0753 sec.\n",
      "iter 150 || Loss: 14.1711 ||timer: 0.0752 sec.\n",
      "iter 160 || Loss: 14.2845 ||timer: 0.0772 sec.\n",
      "iter 170 || Loss: 9.3257 ||timer: 0.0757 sec.\n",
      "iter 180 || Loss: 8.8763 ||timer: 0.0759 sec.\n",
      "iter 190 || Loss: 8.2257 ||timer: 0.0753 sec.\n",
      "iter 200 || Loss: 10.4218 ||timer: 0.0749 sec.\n",
      "iter 210 || Loss: 10.0546 ||timer: 0.0753 sec.\n",
      "iter 220 || Loss: 9.5746 ||timer: 0.0752 sec.\n",
      "iter 230 || Loss: 9.4554 ||timer: 0.0752 sec.\n",
      "iter 240 || Loss: 10.2812 ||timer: 0.0747 sec.\n",
      "iter 250 || Loss: 11.8657 ||timer: 0.0751 sec.\n",
      "iter 260 || Loss: 11.9219 ||timer: 0.0755 sec.\n",
      "iter 270 || Loss: 12.4647 ||timer: 0.0748 sec.\n",
      "iter 280 || Loss: 15.8675 ||timer: 0.0751 sec.\n",
      "iter 290 || Loss: 12.3764 ||timer: 0.0751 sec.\n",
      "iter 300 || Loss: 15.4612 ||timer: 0.0752 sec.\n",
      "iter 310 || Loss: 15.6699 ||timer: 0.0755 sec.\n",
      "iter 320 || Loss: 8.6671 ||timer: 0.0755 sec.\n",
      "iter 330 || Loss: 12.2717 ||timer: 0.0764 sec.\n",
      "iter 340 || Loss: 6.3994 ||timer: 0.0769 sec.\n",
      "iter 350 || Loss: 5.5460 ||timer: 0.0799 sec.\n",
      "iter 360 || Loss: 6.3828 ||timer: 0.0749 sec.\n",
      "iter 370 || Loss: 8.5813 ||timer: 0.0756 sec.\n",
      "iter 380 || Loss: 6.8874 ||timer: 0.0759 sec.\n",
      "iter 390 || Loss: 7.7367 ||timer: 0.0754 sec.\n",
      "iter 400 || Loss: 16.9177 ||timer: 0.0761 sec.\n",
      "iter 410 || Loss: 7.5066 ||timer: 0.0769 sec.\n",
      "iter 420 || Loss: 5.8955 ||timer: 0.0753 sec.\n",
      "iter 430 || Loss: 7.9380 ||timer: 0.0755 sec.\n",
      "iter 440 || Loss: 6.9104 ||timer: 0.0761 sec.\n",
      "iter 450 || Loss: 8.7160 ||timer: 0.0759 sec.\n",
      "iter 460 || Loss: 9.7324 ||timer: 0.0754 sec.\n",
      "iter 470 || Loss: 8.4154 ||timer: 0.0758 sec.\n",
      "iter 480 || Loss: 5.2940 ||timer: 0.0756 sec.\n",
      "iter 490 || Loss: 10.8612 ||timer: 0.0755 sec.\n",
      "iter 500 || Loss: 8.8707 ||Saving state, iter: 500\n",
      "timer: 0.0756 sec.\n",
      "iter 510 || Loss: 8.3644 ||timer: 0.0752 sec.\n",
      "iter 520 || Loss: 7.8109 ||timer: 0.0752 sec.\n",
      "iter 530 || Loss: 7.9830 ||timer: 0.0754 sec.\n",
      "iter 540 || Loss: 8.1905 ||timer: 0.0774 sec.\n",
      "iter 550 || Loss: 7.5746 ||timer: 0.0754 sec.\n",
      "iter 560 || Loss: 9.7968 ||timer: 0.0750 sec.\n",
      "iter 570 || Loss: 11.1480 ||timer: 0.0754 sec.\n",
      "iter 580 || Loss: 6.4948 ||timer: 0.0756 sec.\n",
      "iter 590 || Loss: 7.5823 ||timer: 0.0753 sec.\n",
      "iter 600 || Loss: 6.9211 ||timer: 0.0761 sec.\n",
      "iter 610 || Loss: 5.6466 ||timer: 0.0761 sec.\n",
      "iter 620 || Loss: 8.9643 ||timer: 0.0755 sec.\n",
      "iter 630 || Loss: 6.3597 ||timer: 0.0757 sec.\n",
      "iter 640 || Loss: 5.8219 ||timer: 0.0753 sec.\n",
      "iter 650 || Loss: 8.9225 ||timer: 0.0763 sec.\n",
      "iter 660 || Loss: 5.0637 ||timer: 0.0754 sec.\n",
      "iter 670 || Loss: 12.0918 ||timer: 0.0749 sec.\n",
      "iter 680 || Loss: 8.4433 ||timer: 0.0749 sec.\n",
      "iter 690 || Loss: 8.2184 ||timer: 0.0752 sec.\n",
      "iter 700 || Loss: 7.1983 ||timer: 0.0760 sec.\n",
      "iter 710 || Loss: 7.3431 ||timer: 0.0765 sec.\n",
      "iter 720 || Loss: 6.9542 ||timer: 0.0760 sec.\n",
      "iter 730 || Loss: 6.4731 ||timer: 0.0754 sec.\n",
      "iter 740 || Loss: 6.7546 ||timer: 0.0755 sec.\n",
      "iter 750 || Loss: 5.6952 ||timer: 0.0766 sec.\n",
      "iter 760 || Loss: 7.0382 ||timer: 0.0757 sec.\n",
      "iter 770 || Loss: 4.2341 ||timer: 0.0753 sec.\n",
      "iter 780 || Loss: 13.6925 ||timer: 0.0762 sec.\n",
      "iter 790 || Loss: 3.2301 ||timer: 0.0754 sec.\n",
      "iter 800 || Loss: 7.5927 ||timer: 0.0766 sec.\n",
      "iter 810 || Loss: 9.1645 ||timer: 0.0761 sec.\n",
      "iter 820 || Loss: 9.0172 ||timer: 0.0754 sec.\n",
      "iter 830 || Loss: 8.3219 ||timer: 0.0759 sec.\n",
      "iter 840 || Loss: 5.1336 ||timer: 0.0756 sec.\n",
      "iter 850 || Loss: 10.4267 ||timer: 0.0756 sec.\n",
      "iter 860 || Loss: 4.7219 ||timer: 0.0760 sec.\n",
      "iter 870 || Loss: 4.2373 ||timer: 0.0757 sec.\n",
      "iter 880 || Loss: 11.0528 ||timer: 0.0756 sec.\n",
      "iter 890 || Loss: 4.8003 ||timer: 0.0762 sec.\n",
      "iter 900 || Loss: 6.7409 ||timer: 0.0756 sec.\n",
      "iter 910 || Loss: 5.3281 ||timer: 0.0760 sec.\n",
      "iter 920 || Loss: 6.2883 ||timer: 0.0757 sec.\n",
      "iter 930 || Loss: 15.4318 ||timer: 0.0761 sec.\n",
      "iter 940 || Loss: 4.9726 ||timer: 0.0755 sec.\n",
      "iter 950 || Loss: 5.5373 ||timer: 0.0753 sec.\n",
      "iter 960 || Loss: 5.1853 ||timer: 0.0754 sec.\n",
      "iter 970 || Loss: 8.3256 ||timer: 0.0767 sec.\n",
      "iter 980 || Loss: 5.5975 ||timer: 0.0760 sec.\n",
      "iter 990 || Loss: 5.0263 ||timer: 0.0750 sec.\n",
      "iter 1000 || Loss: 9.4644 ||Saving state, iter: 1000\n",
      "timer: 0.0760 sec.\n",
      "iter 1010 || Loss: 6.1512 ||timer: 0.0768 sec.\n",
      "iter 1020 || Loss: 5.2040 ||timer: 0.0754 sec.\n",
      "iter 1030 || Loss: 9.4530 ||timer: 0.0758 sec.\n",
      "iter 1040 || Loss: 8.0531 ||timer: 0.0752 sec.\n",
      "iter 1050 || Loss: 6.5189 ||timer: 0.0767 sec.\n",
      "iter 1060 || Loss: 10.2234 ||timer: 0.0763 sec.\n",
      "iter 1070 || Loss: 6.4466 ||timer: 0.0757 sec.\n",
      "iter 1080 || Loss: 6.7988 ||timer: 0.0760 sec.\n",
      "iter 1090 || Loss: 8.1152 ||timer: 0.0757 sec.\n",
      "iter 1100 || Loss: 6.0859 ||timer: 0.0754 sec.\n",
      "iter 1110 || Loss: 9.9937 ||timer: 0.0760 sec.\n",
      "iter 1120 || Loss: 12.1524 ||timer: 0.0756 sec.\n",
      "iter 1130 || Loss: 6.5757 ||timer: 0.0759 sec.\n",
      "iter 1140 || Loss: 4.9667 ||timer: 0.0772 sec.\n",
      "iter 1150 || Loss: 5.7014 ||timer: 0.0762 sec.\n",
      "iter 1160 || Loss: 7.7238 ||timer: 0.0765 sec.\n",
      "iter 1170 || Loss: 4.8885 ||timer: 0.0757 sec.\n",
      "iter 1180 || Loss: 5.3287 ||timer: 0.0765 sec.\n",
      "iter 1190 || Loss: 4.6402 ||timer: 0.0749 sec.\n",
      "iter 1200 || Loss: 7.8662 ||timer: 0.0760 sec.\n",
      "iter 1210 || Loss: 7.3264 ||timer: 0.0750 sec.\n",
      "iter 1220 || Loss: 5.6877 ||timer: 0.0791 sec.\n",
      "iter 1230 || Loss: 11.6774 ||timer: 0.0761 sec.\n",
      "iter 1240 || Loss: 11.5643 ||timer: 0.0777 sec.\n",
      "iter 1250 || Loss: 10.1680 ||timer: 0.0759 sec.\n",
      "iter 1260 || Loss: 6.6693 ||timer: 0.0765 sec.\n",
      "iter 1270 || Loss: 5.5792 ||timer: 0.0788 sec.\n",
      "iter 1280 || Loss: 5.6866 ||timer: 0.0752 sec.\n",
      "iter 1290 || Loss: 8.1983 ||timer: 0.0751 sec.\n",
      "iter 1300 || Loss: 8.5678 ||timer: 0.0761 sec.\n",
      "iter 1310 || Loss: 5.3045 ||timer: 0.0757 sec.\n",
      "iter 1320 || Loss: 7.3985 ||timer: 0.0765 sec.\n",
      "iter 1330 || Loss: 9.0622 ||timer: 0.0782 sec.\n",
      "iter 1340 || Loss: 5.1692 ||timer: 0.0794 sec.\n",
      "iter 1350 || Loss: 6.3280 ||timer: 0.0775 sec.\n",
      "iter 1360 || Loss: 6.5293 ||timer: 0.0756 sec.\n",
      "iter 1370 || Loss: 8.0271 ||timer: 0.0755 sec.\n",
      "iter 1380 || Loss: 4.3580 ||timer: 0.0765 sec.\n",
      "iter 1390 || Loss: 9.2968 ||timer: 0.0772 sec.\n",
      "iter 1400 || Loss: 4.4317 ||timer: 0.0761 sec.\n",
      "iter 1410 || Loss: 6.4427 ||timer: 0.0773 sec.\n",
      "iter 1420 || Loss: 5.1727 ||timer: 0.0779 sec.\n",
      "iter 1430 || Loss: 9.5146 ||timer: 0.0775 sec.\n",
      "iter 1440 || Loss: 5.0410 ||timer: 0.0768 sec.\n",
      "iter 1450 || Loss: 5.2010 ||timer: 0.0799 sec.\n",
      "iter 1460 || Loss: 4.5367 ||timer: 0.0756 sec.\n",
      "iter 1470 || Loss: 4.5592 ||timer: 0.0772 sec.\n",
      "iter 1480 || Loss: 5.0923 ||timer: 0.0804 sec.\n",
      "iter 1490 || Loss: 6.5939 ||timer: 0.0756 sec.\n",
      "iter 1500 || Loss: 5.6010 ||Saving state, iter: 1500\n",
      "timer: 0.0763 sec.\n",
      "iter 1510 || Loss: 4.6042 ||timer: 0.0753 sec.\n",
      "iter 1520 || Loss: 5.3561 ||timer: 0.0767 sec.\n",
      "iter 1530 || Loss: 9.1116 ||timer: 0.0776 sec.\n",
      "iter 1540 || Loss: 5.7165 ||timer: 0.0755 sec.\n",
      "iter 1550 || Loss: 5.2880 ||timer: 0.0786 sec.\n",
      "iter 1560 || Loss: 8.6591 ||timer: 0.0758 sec.\n",
      "iter 1570 || Loss: 5.8229 ||timer: 0.0751 sec.\n",
      "iter 1580 || Loss: 6.3607 ||timer: 0.0771 sec.\n",
      "iter 1590 || Loss: 4.7080 ||timer: 0.0792 sec.\n",
      "iter 1600 || Loss: 5.2496 ||timer: 0.0803 sec.\n",
      "iter 1610 || Loss: 6.9295 ||timer: 0.0782 sec.\n",
      "iter 1620 || Loss: 5.6844 ||timer: 0.0765 sec.\n",
      "iter 1630 || Loss: 10.9021 ||timer: 0.0775 sec.\n",
      "iter 1640 || Loss: 8.0750 ||timer: 0.0767 sec.\n",
      "iter 1650 || Loss: 7.2567 ||timer: 1.2620 sec.\n",
      "iter 1660 || Loss: 5.0678 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0758 sec.\n",
      "iter 1670 || Loss: 7.6885 ||timer: 0.0761 sec.\n",
      "iter 1680 || Loss: 4.5052 ||timer: 0.0780 sec.\n",
      "iter 1690 || Loss: 6.0198 ||timer: 0.0781 sec.\n",
      "iter 1700 || Loss: 5.2380 ||timer: 0.0767 sec.\n",
      "iter 1710 || Loss: 5.3748 ||timer: 0.0761 sec.\n",
      "iter 1720 || Loss: 5.1114 ||timer: 0.0796 sec.\n",
      "iter 1730 || Loss: 8.1485 ||timer: 0.0761 sec.\n",
      "iter 1740 || Loss: 5.6234 ||timer: 0.0774 sec.\n",
      "iter 1750 || Loss: 6.3943 ||timer: 0.0759 sec.\n",
      "iter 1760 || Loss: 5.6240 ||timer: 0.0756 sec.\n",
      "iter 1770 || Loss: 6.2017 ||timer: 0.0755 sec.\n",
      "iter 1780 || Loss: 5.3456 ||timer: 0.0772 sec.\n",
      "iter 1790 || Loss: 5.2520 ||timer: 0.0766 sec.\n",
      "iter 1800 || Loss: 9.8484 ||timer: 0.0758 sec.\n",
      "iter 1810 || Loss: 6.4517 ||timer: 0.0766 sec.\n",
      "iter 1820 || Loss: 3.7072 ||timer: 0.0788 sec.\n",
      "iter 1830 || Loss: 9.3874 ||timer: 0.0761 sec.\n",
      "iter 1840 || Loss: 7.5446 ||timer: 0.0771 sec.\n",
      "iter 1850 || Loss: 5.0596 ||timer: 0.0757 sec.\n",
      "iter 1860 || Loss: 4.5784 ||timer: 0.0798 sec.\n",
      "iter 1870 || Loss: 4.3188 ||timer: 0.0755 sec.\n",
      "iter 1880 || Loss: 5.3615 ||timer: 0.0796 sec.\n",
      "iter 1890 || Loss: 3.4857 ||timer: 0.0784 sec.\n",
      "iter 1900 || Loss: 15.7072 ||timer: 0.0767 sec.\n",
      "iter 1910 || Loss: 8.7103 ||timer: 0.0764 sec.\n",
      "iter 1920 || Loss: 3.6419 ||timer: 0.0794 sec.\n",
      "iter 1930 || Loss: 6.1641 ||timer: 0.0772 sec.\n",
      "iter 1940 || Loss: 12.4262 ||timer: 0.0794 sec.\n",
      "iter 1950 || Loss: 6.6887 ||timer: 0.0782 sec.\n",
      "iter 1960 || Loss: 5.8120 ||timer: 0.0772 sec.\n",
      "iter 1970 || Loss: 9.0186 ||timer: 0.0804 sec.\n",
      "iter 1980 || Loss: 5.9388 ||timer: 0.0772 sec.\n",
      "iter 1990 || Loss: 7.2787 ||timer: 0.0786 sec.\n",
      "iter 2000 || Loss: 5.9248 ||Saving state, iter: 2000\n",
      "timer: 0.0785 sec.\n",
      "iter 2010 || Loss: 4.2384 ||timer: 0.0775 sec.\n",
      "iter 2020 || Loss: 9.6757 ||timer: 0.0815 sec.\n",
      "iter 2030 || Loss: 5.1796 ||timer: 0.0809 sec.\n",
      "iter 2040 || Loss: 4.6152 ||timer: 0.0790 sec.\n",
      "iter 2050 || Loss: 5.8204 ||timer: 0.0789 sec.\n",
      "iter 2060 || Loss: 6.3361 ||timer: 0.0790 sec.\n",
      "iter 2070 || Loss: 6.0327 ||timer: 0.0773 sec.\n",
      "iter 2080 || Loss: 4.9501 ||timer: 0.0771 sec.\n",
      "iter 2090 || Loss: 9.8195 ||timer: 0.0807 sec.\n",
      "iter 2100 || Loss: 5.0472 ||timer: 0.0788 sec.\n",
      "iter 2110 || Loss: 4.0329 ||timer: 0.0804 sec.\n",
      "iter 2120 || Loss: 5.7799 ||timer: 0.0788 sec.\n",
      "iter 2130 || Loss: 3.8642 ||timer: 0.0784 sec.\n",
      "iter 2140 || Loss: 4.2237 ||timer: 0.0775 sec.\n",
      "iter 2150 || Loss: 7.0982 ||timer: 0.0763 sec.\n",
      "iter 2160 || Loss: 11.7884 ||timer: 0.0757 sec.\n",
      "iter 2170 || Loss: 3.9009 ||timer: 0.0762 sec.\n",
      "iter 2180 || Loss: 7.9406 ||timer: 0.0811 sec.\n",
      "iter 2190 || Loss: 4.2141 ||timer: 0.0757 sec.\n",
      "iter 2200 || Loss: 4.5112 ||timer: 0.0770 sec.\n",
      "iter 2210 || Loss: 2.8516 ||timer: 0.0764 sec.\n",
      "iter 2220 || Loss: 4.5533 ||timer: 0.0772 sec.\n",
      "iter 2230 || Loss: 2.7337 ||timer: 0.0769 sec.\n",
      "iter 2240 || Loss: 2.6876 ||timer: 0.0758 sec.\n",
      "iter 2250 || Loss: 2.0182 ||timer: 0.0791 sec.\n",
      "iter 2260 || Loss: 4.3327 ||timer: 0.0785 sec.\n",
      "iter 2270 || Loss: 3.8473 ||timer: 0.0780 sec.\n",
      "iter 2280 || Loss: 6.4716 ||timer: 0.0795 sec.\n",
      "iter 2290 || Loss: 2.5756 ||timer: 0.0759 sec.\n",
      "iter 2300 || Loss: 3.6634 ||timer: 0.0765 sec.\n",
      "iter 2310 || Loss: 5.3015 ||timer: 0.0776 sec.\n",
      "iter 2320 || Loss: 4.9416 ||timer: 0.0796 sec.\n",
      "iter 2330 || Loss: 5.2915 ||timer: 0.0768 sec.\n",
      "iter 2340 || Loss: 5.8597 ||timer: 0.0781 sec.\n",
      "iter 2350 || Loss: 5.9656 ||timer: 0.0801 sec.\n",
      "iter 2360 || Loss: 5.2664 ||timer: 0.0786 sec.\n",
      "iter 2370 || Loss: 6.6080 ||timer: 0.0814 sec.\n",
      "iter 2380 || Loss: 8.5753 ||timer: 0.0780 sec.\n",
      "iter 2390 || Loss: 5.3303 ||timer: 0.0771 sec.\n",
      "iter 2400 || Loss: 4.1618 ||timer: 0.0762 sec.\n",
      "iter 2410 || Loss: 3.4986 ||timer: 0.0770 sec.\n",
      "iter 2420 || Loss: 6.0592 ||timer: 0.0785 sec.\n",
      "iter 2430 || Loss: 15.4367 ||timer: 0.0784 sec.\n",
      "iter 2440 || Loss: 5.2239 ||timer: 0.0775 sec.\n",
      "iter 2450 || Loss: 7.4677 ||timer: 0.0782 sec.\n",
      "iter 2460 || Loss: 6.1280 ||timer: 0.0800 sec.\n",
      "iter 2470 || Loss: 4.8423 ||timer: 0.0790 sec.\n",
      "iter 2480 || Loss: 3.1864 ||timer: 0.0757 sec.\n",
      "iter 2490 || Loss: 4.0802 ||timer: 0.0784 sec.\n",
      "iter 2500 || Loss: 5.3233 ||Saving state, iter: 2500\n",
      "timer: 0.0758 sec.\n",
      "iter 2510 || Loss: 6.1000 ||timer: 0.0788 sec.\n",
      "iter 2520 || Loss: 4.2393 ||timer: 0.0772 sec.\n",
      "iter 2530 || Loss: 5.3316 ||timer: 0.0773 sec.\n",
      "iter 2540 || Loss: 4.5853 ||timer: 0.0785 sec.\n",
      "iter 2550 || Loss: 6.6753 ||timer: 0.0792 sec.\n",
      "iter 2560 || Loss: 8.4062 ||timer: 0.0785 sec.\n",
      "iter 2570 || Loss: 3.6988 ||timer: 0.0806 sec.\n",
      "iter 2580 || Loss: 3.1641 ||timer: 0.0779 sec.\n",
      "iter 2590 || Loss: 9.5716 ||timer: 0.0782 sec.\n",
      "iter 2600 || Loss: 5.4399 ||timer: 0.0761 sec.\n",
      "iter 2610 || Loss: 3.5640 ||timer: 0.0795 sec.\n",
      "iter 2620 || Loss: 4.7952 ||timer: 0.0773 sec.\n",
      "iter 2630 || Loss: 3.1473 ||timer: 0.0802 sec.\n",
      "iter 2640 || Loss: 4.6752 ||timer: 0.0779 sec.\n",
      "iter 2650 || Loss: 8.0078 ||timer: 0.0795 sec.\n",
      "iter 2660 || Loss: 3.5387 ||timer: 0.0766 sec.\n",
      "iter 2670 || Loss: 5.6044 ||timer: 0.0782 sec.\n",
      "iter 2680 || Loss: 8.0046 ||timer: 0.0761 sec.\n",
      "iter 2690 || Loss: 4.3553 ||timer: 0.0784 sec.\n",
      "iter 2700 || Loss: 5.4977 ||timer: 0.0765 sec.\n",
      "iter 2710 || Loss: 2.7948 ||timer: 0.0898 sec.\n",
      "iter 2720 || Loss: 3.3354 ||timer: 0.0792 sec.\n",
      "iter 2730 || Loss: 6.4244 ||timer: 0.0760 sec.\n",
      "iter 2740 || Loss: 6.1217 ||timer: 0.0794 sec.\n",
      "iter 2750 || Loss: 5.1605 ||timer: 0.0801 sec.\n",
      "iter 2760 || Loss: 7.8679 ||timer: 0.0763 sec.\n",
      "iter 2770 || Loss: 8.2010 ||timer: 0.0765 sec.\n",
      "iter 2780 || Loss: 5.8984 ||timer: 0.0813 sec.\n",
      "iter 2790 || Loss: 4.8459 ||timer: 0.0762 sec.\n",
      "iter 2800 || Loss: 3.5782 ||timer: 0.0784 sec.\n",
      "iter 2810 || Loss: 5.0052 ||timer: 0.0807 sec.\n",
      "iter 2820 || Loss: 4.2407 ||timer: 0.0785 sec.\n",
      "iter 2830 || Loss: 10.2114 ||timer: 0.0798 sec.\n",
      "iter 2840 || Loss: 5.2565 ||timer: 0.0798 sec.\n",
      "iter 2850 || Loss: 3.9876 ||timer: 0.0780 sec.\n",
      "iter 2860 || Loss: 4.1263 ||timer: 0.0784 sec.\n",
      "iter 2870 || Loss: 3.4332 ||timer: 0.0795 sec.\n",
      "iter 2880 || Loss: 5.3477 ||timer: 0.0763 sec.\n",
      "iter 2890 || Loss: 4.3495 ||timer: 0.0778 sec.\n",
      "iter 2900 || Loss: 8.9260 ||timer: 0.0805 sec.\n",
      "iter 2910 || Loss: 4.1421 ||timer: 0.0766 sec.\n",
      "iter 2920 || Loss: 8.7642 ||timer: 0.0784 sec.\n",
      "iter 2930 || Loss: 6.9045 ||timer: 0.0766 sec.\n",
      "iter 2940 || Loss: 10.1119 ||timer: 0.0761 sec.\n",
      "iter 2950 || Loss: 6.9511 ||timer: 0.0783 sec.\n",
      "iter 2960 || Loss: 5.3074 ||timer: 0.0776 sec.\n",
      "iter 2970 || Loss: 4.4258 ||timer: 0.0798 sec.\n",
      "iter 2980 || Loss: 6.3541 ||timer: 0.0778 sec.\n",
      "iter 2990 || Loss: 4.7866 ||timer: 0.0798 sec.\n",
      "iter 3000 || Loss: 4.0395 ||Saving state, iter: 3000\n",
      "timer: 0.0776 sec.\n",
      "iter 3010 || Loss: 6.8215 ||timer: 0.0783 sec.\n",
      "iter 3020 || Loss: 6.4471 ||timer: 0.0768 sec.\n",
      "iter 3030 || Loss: 7.7902 ||timer: 0.0831 sec.\n",
      "iter 3040 || Loss: 4.7314 ||timer: 0.0783 sec.\n",
      "iter 3050 || Loss: 6.3375 ||timer: 0.0802 sec.\n",
      "iter 3060 || Loss: 4.7859 ||timer: 0.0804 sec.\n",
      "iter 3070 || Loss: 3.5402 ||timer: 0.0788 sec.\n",
      "iter 3080 || Loss: 4.9180 ||timer: 0.0774 sec.\n",
      "iter 3090 || Loss: 6.4319 ||timer: 0.0782 sec.\n",
      "iter 3100 || Loss: 10.2034 ||timer: 0.0780 sec.\n",
      "iter 3110 || Loss: 4.1739 ||timer: 0.0797 sec.\n",
      "iter 3120 || Loss: 9.1058 ||timer: 0.0767 sec.\n",
      "iter 3130 || Loss: 4.0790 ||timer: 0.0768 sec.\n",
      "iter 3140 || Loss: 5.9689 ||timer: 0.0773 sec.\n",
      "iter 3150 || Loss: 10.4310 ||timer: 0.0783 sec.\n",
      "iter 3160 || Loss: 6.1826 ||timer: 0.0757 sec.\n",
      "iter 3170 || Loss: 7.0221 ||timer: 0.0799 sec.\n",
      "iter 3180 || Loss: 4.7093 ||timer: 0.0804 sec.\n",
      "iter 3190 || Loss: 4.9666 ||timer: 0.0760 sec.\n",
      "iter 3200 || Loss: 5.7702 ||timer: 0.0783 sec.\n",
      "iter 3210 || Loss: 6.5240 ||timer: 0.0763 sec.\n",
      "iter 3220 || Loss: 3.5980 ||timer: 0.0771 sec.\n",
      "iter 3230 || Loss: 5.5625 ||timer: 0.0800 sec.\n",
      "iter 3240 || Loss: 4.9848 ||timer: 0.0796 sec.\n",
      "iter 3250 || Loss: 3.2052 ||timer: 0.0784 sec.\n",
      "iter 3260 || Loss: 3.9610 ||timer: 0.0784 sec.\n",
      "iter 3270 || Loss: 3.8883 ||timer: 0.0786 sec.\n",
      "iter 3280 || Loss: 4.9589 ||timer: 0.0796 sec.\n",
      "iter 3290 || Loss: 3.6955 ||timer: 0.0764 sec.\n",
      "iter 3300 || Loss: 5.3301 ||timer: 0.0801 sec.\n",
      "iter 3310 || Loss: 2.7126 ||timer: 0.0766 sec.\n",
      "iter 3320 || Loss: 6.6561 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0764 sec.\n",
      "iter 3330 || Loss: 4.3774 ||timer: 0.0771 sec.\n",
      "iter 3340 || Loss: 2.9063 ||timer: 0.0767 sec.\n",
      "iter 3350 || Loss: 4.1566 ||timer: 0.0764 sec.\n",
      "iter 3360 || Loss: 2.9506 ||timer: 0.0770 sec.\n",
      "iter 3370 || Loss: 2.7574 ||timer: 0.0788 sec.\n",
      "iter 3380 || Loss: 3.7676 ||timer: 0.0794 sec.\n",
      "iter 3390 || Loss: 4.7076 ||timer: 0.0808 sec.\n",
      "iter 3400 || Loss: 3.4269 ||timer: 0.0789 sec.\n",
      "iter 3410 || Loss: 5.7695 ||timer: 0.0758 sec.\n",
      "iter 3420 || Loss: 5.1420 ||timer: 0.0811 sec.\n",
      "iter 3430 || Loss: 4.1176 ||timer: 0.0779 sec.\n",
      "iter 3440 || Loss: 10.5054 ||timer: 0.0761 sec.\n",
      "iter 3450 || Loss: 3.1772 ||timer: 0.0795 sec.\n",
      "iter 3460 || Loss: 6.4088 ||timer: 0.0784 sec.\n",
      "iter 3470 || Loss: 3.5233 ||timer: 0.0764 sec.\n",
      "iter 3480 || Loss: 2.5028 ||timer: 0.0803 sec.\n",
      "iter 3490 || Loss: 3.3441 ||timer: 0.0786 sec.\n",
      "iter 3500 || Loss: 6.6212 ||Saving state, iter: 3500\n",
      "timer: 0.0771 sec.\n",
      "iter 3510 || Loss: 7.2300 ||timer: 0.0783 sec.\n",
      "iter 3520 || Loss: 7.2096 ||timer: 0.0808 sec.\n",
      "iter 3530 || Loss: 6.0202 ||timer: 0.0782 sec.\n",
      "iter 3540 || Loss: 4.5063 ||timer: 0.0778 sec.\n",
      "iter 3550 || Loss: 6.2851 ||timer: 0.0766 sec.\n",
      "iter 3560 || Loss: 3.8089 ||timer: 0.0796 sec.\n",
      "iter 3570 || Loss: 4.7096 ||timer: 0.0801 sec.\n",
      "iter 3580 || Loss: 4.1946 ||timer: 0.0810 sec.\n",
      "iter 3590 || Loss: 4.0410 ||timer: 0.0792 sec.\n",
      "iter 3600 || Loss: 3.0354 ||timer: 0.0782 sec.\n",
      "iter 3610 || Loss: 5.4398 ||timer: 0.0796 sec.\n",
      "iter 3620 || Loss: 4.4452 ||timer: 0.0796 sec.\n",
      "iter 3630 || Loss: 6.5690 ||timer: 0.0797 sec.\n",
      "iter 3640 || Loss: 3.2837 ||timer: 0.0807 sec.\n",
      "iter 3650 || Loss: 3.9678 ||timer: 0.0795 sec.\n",
      "iter 3660 || Loss: 10.1896 ||timer: 0.0782 sec.\n",
      "iter 3670 || Loss: 3.1935 ||timer: 0.0788 sec.\n",
      "iter 3680 || Loss: 2.1934 ||timer: 0.0798 sec.\n",
      "iter 3690 || Loss: 5.8847 ||timer: 0.0767 sec.\n",
      "iter 3700 || Loss: 7.8227 ||timer: 0.0760 sec.\n",
      "iter 3710 || Loss: 9.3013 ||timer: 0.0784 sec.\n",
      "iter 3720 || Loss: 4.6325 ||timer: 0.0777 sec.\n",
      "iter 3730 || Loss: 4.5147 ||timer: 0.0767 sec.\n",
      "iter 3740 || Loss: 8.0798 ||timer: 0.0802 sec.\n",
      "iter 3750 || Loss: 3.4684 ||timer: 0.0810 sec.\n",
      "iter 3760 || Loss: 2.6917 ||timer: 0.0775 sec.\n",
      "iter 3770 || Loss: 4.2808 ||timer: 0.0777 sec.\n",
      "iter 3780 || Loss: 4.8427 ||timer: 0.0794 sec.\n",
      "iter 3790 || Loss: 4.7221 ||timer: 0.0772 sec.\n",
      "iter 3800 || Loss: 6.0105 ||timer: 0.0791 sec.\n",
      "iter 3810 || Loss: 12.9941 ||timer: 0.0804 sec.\n",
      "iter 3820 || Loss: 5.0343 ||timer: 0.0759 sec.\n",
      "iter 3830 || Loss: 4.3538 ||timer: 0.0766 sec.\n",
      "iter 3840 || Loss: 7.9038 ||timer: 0.0789 sec.\n",
      "iter 3850 || Loss: 4.9197 ||timer: 0.0794 sec.\n",
      "iter 3860 || Loss: 4.1971 ||timer: 0.0793 sec.\n",
      "iter 3870 || Loss: 4.5692 ||timer: 0.0773 sec.\n",
      "iter 3880 || Loss: 4.9095 ||timer: 0.0762 sec.\n",
      "iter 3890 || Loss: 7.9854 ||timer: 0.0774 sec.\n",
      "iter 3900 || Loss: 5.0972 ||timer: 0.0774 sec.\n",
      "iter 3910 || Loss: 2.4521 ||timer: 0.0792 sec.\n",
      "iter 3920 || Loss: 4.6192 ||timer: 0.0781 sec.\n",
      "iter 3930 || Loss: 8.5087 ||timer: 0.0766 sec.\n",
      "iter 3940 || Loss: 1.8904 ||timer: 0.0767 sec.\n",
      "iter 3950 || Loss: 2.5096 ||timer: 0.0774 sec.\n",
      "iter 3960 || Loss: 2.7938 ||timer: 0.0785 sec.\n",
      "iter 3970 || Loss: 4.5918 ||timer: 0.0796 sec.\n",
      "iter 3980 || Loss: 8.2058 ||timer: 0.0803 sec.\n",
      "iter 3990 || Loss: 4.8419 ||Change learning rate to:  0.0001\n",
      "timer: 0.0803 sec.\n",
      "iter 4000 || Loss: 3.5687 ||Saving state, iter: 4000\n",
      "timer: 0.0762 sec.\n",
      "iter 4010 || Loss: 3.8995 ||timer: 0.0765 sec.\n",
      "iter 4020 || Loss: 2.3033 ||timer: 0.0775 sec.\n",
      "iter 4030 || Loss: 5.6112 ||timer: 0.0785 sec.\n",
      "iter 4040 || Loss: 4.0726 ||timer: 0.0762 sec.\n",
      "iter 4050 || Loss: 2.6987 ||timer: 0.0819 sec.\n",
      "iter 4060 || Loss: 1.9273 ||timer: 0.0779 sec.\n",
      "iter 4070 || Loss: 3.7664 ||timer: 0.0766 sec.\n",
      "iter 4080 || Loss: 2.7294 ||timer: 0.0786 sec.\n",
      "iter 4090 || Loss: 4.3584 ||timer: 0.0754 sec.\n",
      "iter 4100 || Loss: 3.0193 ||timer: 0.0794 sec.\n",
      "iter 4110 || Loss: 4.2173 ||timer: 0.0813 sec.\n",
      "iter 4120 || Loss: 3.1967 ||timer: 0.0788 sec.\n",
      "iter 4130 || Loss: 4.0790 ||timer: 0.0803 sec.\n",
      "iter 4140 || Loss: 3.6706 ||timer: 0.0788 sec.\n",
      "iter 4150 || Loss: 5.0752 ||timer: 0.0778 sec.\n",
      "iter 4160 || Loss: 9.1692 ||timer: 0.0787 sec.\n",
      "iter 4170 || Loss: 2.0456 ||timer: 0.0772 sec.\n",
      "iter 4180 || Loss: 8.0228 ||timer: 0.0770 sec.\n",
      "iter 4190 || Loss: 5.6790 ||timer: 0.0797 sec.\n",
      "iter 4200 || Loss: 3.5694 ||timer: 0.0762 sec.\n",
      "iter 4210 || Loss: 5.0840 ||timer: 0.0761 sec.\n",
      "iter 4220 || Loss: 1.6996 ||timer: 0.0781 sec.\n",
      "iter 4230 || Loss: 1.6477 ||timer: 0.0840 sec.\n",
      "iter 4240 || Loss: 7.4336 ||timer: 0.0757 sec.\n",
      "iter 4250 || Loss: 1.8420 ||timer: 0.0797 sec.\n",
      "iter 4260 || Loss: 1.2932 ||timer: 0.0767 sec.\n",
      "iter 4270 || Loss: 9.1881 ||timer: 0.0759 sec.\n",
      "iter 4280 || Loss: 5.0364 ||timer: 0.0759 sec.\n",
      "iter 4290 || Loss: 1.9089 ||timer: 0.0757 sec.\n",
      "iter 4300 || Loss: 2.7475 ||timer: 0.0760 sec.\n",
      "iter 4310 || Loss: 3.1950 ||timer: 0.0760 sec.\n",
      "iter 4320 || Loss: 2.9036 ||timer: 0.0765 sec.\n",
      "iter 4330 || Loss: 2.3964 ||timer: 0.0796 sec.\n",
      "iter 4340 || Loss: 2.6416 ||timer: 0.0772 sec.\n",
      "iter 4350 || Loss: 4.7478 ||timer: 0.0801 sec.\n",
      "iter 4360 || Loss: 3.3665 ||timer: 0.0771 sec.\n",
      "iter 4370 || Loss: 3.9522 ||timer: 0.0786 sec.\n",
      "iter 4380 || Loss: 2.2595 ||timer: 0.0821 sec.\n",
      "iter 4390 || Loss: 3.0628 ||timer: 0.0775 sec.\n",
      "iter 4400 || Loss: 4.0464 ||timer: 0.0765 sec.\n",
      "iter 4410 || Loss: 1.6473 ||timer: 0.0802 sec.\n",
      "iter 4420 || Loss: 2.0736 ||timer: 0.0803 sec.\n",
      "iter 4430 || Loss: 1.4614 ||timer: 0.0767 sec.\n",
      "iter 4440 || Loss: 3.6757 ||timer: 0.0763 sec.\n",
      "iter 4450 || Loss: 3.5102 ||timer: 0.0760 sec.\n",
      "iter 4460 || Loss: 6.0758 ||timer: 0.0800 sec.\n",
      "iter 4470 || Loss: 1.3928 ||timer: 0.0762 sec.\n",
      "iter 4480 || Loss: 2.5681 ||timer: 0.0764 sec.\n",
      "iter 4490 || Loss: 2.1511 ||timer: 0.0791 sec.\n",
      "iter 4500 || Loss: 1.6057 ||Saving state, iter: 4500\n",
      "timer: 0.0772 sec.\n",
      "iter 4510 || Loss: 3.5087 ||timer: 0.0768 sec.\n",
      "iter 4520 || Loss: 2.6006 ||timer: 0.0798 sec.\n",
      "iter 4530 || Loss: 4.0805 ||timer: 0.0780 sec.\n",
      "iter 4540 || Loss: 2.2485 ||timer: 0.0775 sec.\n",
      "iter 4550 || Loss: 2.5079 ||timer: 0.0769 sec.\n",
      "iter 4560 || Loss: 2.9038 ||timer: 0.0774 sec.\n",
      "iter 4570 || Loss: 1.9577 ||timer: 0.0769 sec.\n",
      "iter 4580 || Loss: 2.3875 ||timer: 0.0792 sec.\n",
      "iter 4590 || Loss: 8.3939 ||timer: 0.0762 sec.\n",
      "iter 4600 || Loss: 2.0380 ||timer: 0.0799 sec.\n",
      "iter 4610 || Loss: 1.9068 ||timer: 0.0777 sec.\n",
      "iter 4620 || Loss: 3.2591 ||timer: 0.0767 sec.\n",
      "iter 4630 || Loss: 2.4107 ||timer: 0.0790 sec.\n",
      "iter 4640 || Loss: 3.5111 ||timer: 0.0761 sec.\n",
      "iter 4650 || Loss: 2.1731 ||timer: 0.0793 sec.\n",
      "iter 4660 || Loss: 2.5875 ||timer: 0.0763 sec.\n",
      "iter 4670 || Loss: 5.0557 ||timer: 0.0769 sec.\n",
      "iter 4680 || Loss: 3.1255 ||timer: 0.0758 sec.\n",
      "iter 4690 || Loss: 3.7415 ||timer: 0.0783 sec.\n",
      "iter 4700 || Loss: 3.5204 ||timer: 0.0778 sec.\n",
      "iter 4710 || Loss: 2.3305 ||timer: 0.0798 sec.\n",
      "iter 4720 || Loss: 1.6462 ||timer: 0.0797 sec.\n",
      "iter 4730 || Loss: 2.2995 ||timer: 0.0775 sec.\n",
      "iter 4740 || Loss: 3.1296 ||timer: 0.0782 sec.\n",
      "iter 4750 || Loss: 2.9480 ||timer: 0.0774 sec.\n",
      "iter 4760 || Loss: 4.2315 ||timer: 0.0797 sec.\n",
      "iter 4770 || Loss: 3.4703 ||timer: 0.0783 sec.\n",
      "iter 4780 || Loss: 3.5860 ||timer: 0.0758 sec.\n",
      "iter 4790 || Loss: 4.2160 ||timer: 0.0764 sec.\n",
      "iter 4800 || Loss: 2.9923 ||timer: 0.0770 sec.\n",
      "iter 4810 || Loss: 1.5712 ||timer: 0.0760 sec.\n",
      "iter 4820 || Loss: 4.2953 ||timer: 0.0795 sec.\n",
      "iter 4830 || Loss: 2.2537 ||timer: 0.0797 sec.\n",
      "iter 4840 || Loss: 3.5144 ||timer: 0.0803 sec.\n",
      "iter 4850 || Loss: 3.7819 ||timer: 0.0772 sec.\n",
      "iter 4860 || Loss: 3.4274 ||timer: 0.0769 sec.\n",
      "iter 4870 || Loss: 3.2175 ||timer: 0.0792 sec.\n",
      "iter 4880 || Loss: 1.4720 ||timer: 0.0769 sec.\n",
      "iter 4890 || Loss: 4.2887 ||timer: 0.0768 sec.\n",
      "iter 4900 || Loss: 4.3745 ||timer: 0.0800 sec.\n",
      "iter 4910 || Loss: 5.7660 ||timer: 0.0764 sec.\n",
      "iter 4920 || Loss: 3.0863 ||timer: 0.0762 sec.\n",
      "iter 4930 || Loss: 2.9365 ||timer: 0.0797 sec.\n",
      "iter 4940 || Loss: 1.9269 ||timer: 0.0769 sec.\n",
      "iter 4950 || Loss: 3.1322 ||timer: 0.0780 sec.\n",
      "iter 4960 || Loss: 1.7569 ||timer: 0.0782 sec.\n",
      "iter 4970 || Loss: 2.8944 ||timer: 0.0748 sec.\n",
      "iter 4980 || Loss: 2.9600 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0764 sec.\n",
      "iter 4990 || Loss: 1.3155 ||timer: 0.0780 sec.\n",
      "iter 5000 || Loss: 7.3176 ||Saving state, iter: 5000\n",
      "timer: 0.0790 sec.\n",
      "iter 5010 || Loss: 2.7471 ||timer: 0.0776 sec.\n",
      "iter 5020 || Loss: 2.8929 ||timer: 0.0787 sec.\n",
      "iter 5030 || Loss: 3.4218 ||timer: 0.0780 sec.\n",
      "iter 5040 || Loss: 2.5491 ||timer: 0.0775 sec.\n",
      "iter 5050 || Loss: 4.6993 ||timer: 0.0760 sec.\n",
      "iter 5060 || Loss: 6.7724 ||timer: 0.0778 sec.\n",
      "iter 5070 || Loss: 1.5540 ||timer: 0.0762 sec.\n",
      "iter 5080 || Loss: 1.9654 ||timer: 0.0803 sec.\n",
      "iter 5090 || Loss: 1.4935 ||timer: 0.0779 sec.\n",
      "iter 5100 || Loss: 5.2281 ||timer: 0.0779 sec.\n",
      "iter 5110 || Loss: 2.0625 ||timer: 0.0766 sec.\n",
      "iter 5120 || Loss: 4.8178 ||timer: 0.0763 sec.\n",
      "iter 5130 || Loss: 3.0878 ||timer: 0.0813 sec.\n",
      "iter 5140 || Loss: 1.4149 ||timer: 0.0754 sec.\n",
      "iter 5150 || Loss: 3.4557 ||timer: 0.0783 sec.\n",
      "iter 5160 || Loss: 2.2278 ||timer: 0.0764 sec.\n",
      "iter 5170 || Loss: 4.3388 ||timer: 0.0763 sec.\n",
      "iter 5180 || Loss: 4.9264 ||timer: 0.0764 sec.\n",
      "iter 5190 || Loss: 4.1476 ||timer: 0.0758 sec.\n",
      "iter 5200 || Loss: 6.6712 ||timer: 0.0763 sec.\n",
      "iter 5210 || Loss: 2.5102 ||timer: 0.0771 sec.\n",
      "iter 5220 || Loss: 8.9244 ||timer: 0.0756 sec.\n",
      "iter 5230 || Loss: 5.8093 ||timer: 0.0772 sec.\n",
      "iter 5240 || Loss: 7.0164 ||timer: 0.0800 sec.\n",
      "iter 5250 || Loss: 2.3544 ||timer: 0.0794 sec.\n",
      "iter 5260 || Loss: 7.5562 ||timer: 0.0804 sec.\n",
      "iter 5270 || Loss: 1.3690 ||timer: 0.0778 sec.\n",
      "iter 5280 || Loss: 2.1127 ||timer: 0.0786 sec.\n",
      "iter 5290 || Loss: 4.2382 ||timer: 0.0781 sec.\n",
      "iter 5300 || Loss: 6.2814 ||timer: 0.0777 sec.\n",
      "iter 5310 || Loss: 1.5529 ||timer: 0.0763 sec.\n",
      "iter 5320 || Loss: 6.3568 ||timer: 0.0761 sec.\n",
      "iter 5330 || Loss: 1.7945 ||timer: 0.0766 sec.\n",
      "iter 5340 || Loss: 3.3177 ||timer: 0.0770 sec.\n",
      "iter 5350 || Loss: 2.1159 ||timer: 0.0765 sec.\n",
      "iter 5360 || Loss: 5.1285 ||timer: 0.0787 sec.\n",
      "iter 5370 || Loss: 2.8678 ||timer: 0.0762 sec.\n",
      "iter 5380 || Loss: 3.7148 ||timer: 0.0761 sec.\n",
      "iter 5390 || Loss: 2.0211 ||timer: 0.0770 sec.\n",
      "iter 5400 || Loss: 1.9052 ||timer: 0.0790 sec.\n",
      "iter 5410 || Loss: 5.5268 ||timer: 0.0775 sec.\n",
      "iter 5420 || Loss: 4.8537 ||timer: 0.0796 sec.\n",
      "iter 5430 || Loss: 2.3663 ||timer: 0.0782 sec.\n",
      "iter 5440 || Loss: 2.4738 ||timer: 0.0795 sec.\n",
      "iter 5450 || Loss: 2.5250 ||timer: 0.0810 sec.\n",
      "iter 5460 || Loss: 1.6441 ||timer: 0.0782 sec.\n",
      "iter 5470 || Loss: 2.2191 ||timer: 0.0789 sec.\n",
      "iter 5480 || Loss: 1.2899 ||timer: 0.0780 sec.\n",
      "iter 5490 || Loss: 2.6947 ||timer: 0.0824 sec.\n",
      "iter 5500 || Loss: 3.0061 ||Saving state, iter: 5500\n",
      "timer: 0.0781 sec.\n",
      "iter 5510 || Loss: 2.1206 ||timer: 0.0804 sec.\n",
      "iter 5520 || Loss: 1.3530 ||timer: 0.0776 sec.\n",
      "iter 5530 || Loss: 1.8290 ||timer: 0.0787 sec.\n",
      "iter 5540 || Loss: 2.2310 ||timer: 0.0769 sec.\n",
      "iter 5550 || Loss: 2.4404 ||timer: 0.0793 sec.\n",
      "iter 5560 || Loss: 3.5059 ||timer: 0.0768 sec.\n",
      "iter 5570 || Loss: 2.8145 ||timer: 0.0778 sec.\n",
      "iter 5580 || Loss: 3.8949 ||timer: 0.0795 sec.\n",
      "iter 5590 || Loss: 2.3659 ||timer: 0.0796 sec.\n",
      "iter 5600 || Loss: 1.6585 ||timer: 0.0773 sec.\n",
      "iter 5610 || Loss: 1.8848 ||timer: 0.0763 sec.\n",
      "iter 5620 || Loss: 4.2526 ||timer: 0.0791 sec.\n",
      "iter 5630 || Loss: 2.1508 ||timer: 0.0770 sec.\n",
      "iter 5640 || Loss: 2.1595 ||timer: 0.0781 sec.\n",
      "iter 5650 || Loss: 2.6158 ||timer: 0.0771 sec.\n",
      "iter 5660 || Loss: 4.1026 ||timer: 0.0762 sec.\n",
      "iter 5670 || Loss: 5.1417 ||timer: 0.0765 sec.\n",
      "iter 5680 || Loss: 5.5770 ||timer: 0.0762 sec.\n",
      "iter 5690 || Loss: 2.4748 ||timer: 0.0781 sec.\n",
      "iter 5700 || Loss: 1.6058 ||timer: 0.0791 sec.\n",
      "iter 5710 || Loss: 5.2230 ||timer: 0.0761 sec.\n",
      "iter 5720 || Loss: 4.7193 ||timer: 0.0769 sec.\n",
      "iter 5730 || Loss: 2.6787 ||timer: 0.0764 sec.\n",
      "iter 5740 || Loss: 5.4492 ||timer: 0.0760 sec.\n",
      "iter 5750 || Loss: 1.7743 ||timer: 0.0765 sec.\n",
      "iter 5760 || Loss: 1.6356 ||timer: 0.0809 sec.\n",
      "iter 5770 || Loss: 3.4035 ||timer: 0.0781 sec.\n",
      "iter 5780 || Loss: 2.0309 ||timer: 0.0774 sec.\n",
      "iter 5790 || Loss: 3.9137 ||timer: 0.0787 sec.\n",
      "iter 5800 || Loss: 2.1519 ||timer: 0.0790 sec.\n",
      "iter 5810 || Loss: 2.7514 ||timer: 0.0773 sec.\n",
      "iter 5820 || Loss: 2.3587 ||timer: 0.0805 sec.\n",
      "iter 5830 || Loss: 3.2367 ||timer: 0.0795 sec.\n",
      "iter 5840 || Loss: 4.1584 ||timer: 0.0807 sec.\n",
      "iter 5850 || Loss: 3.4625 ||timer: 0.0760 sec.\n",
      "iter 5860 || Loss: 2.5700 ||timer: 0.0785 sec.\n",
      "iter 5870 || Loss: 3.8565 ||timer: 0.0779 sec.\n",
      "iter 5880 || Loss: 3.7406 ||timer: 0.0756 sec.\n",
      "iter 5890 || Loss: 6.2122 ||timer: 0.0769 sec.\n",
      "iter 5900 || Loss: 6.4847 ||timer: 0.0802 sec.\n",
      "iter 5910 || Loss: 1.3450 ||timer: 0.0790 sec.\n",
      "iter 5920 || Loss: 3.2319 ||timer: 0.0763 sec.\n",
      "iter 5930 || Loss: 3.8398 ||timer: 0.0772 sec.\n",
      "iter 5940 || Loss: 2.8003 ||timer: 0.0768 sec.\n",
      "iter 5950 || Loss: 2.8270 ||timer: 0.0778 sec.\n",
      "iter 5960 || Loss: 3.3580 ||timer: 0.0793 sec.\n",
      "iter 5970 || Loss: 2.2894 ||timer: 0.0788 sec.\n",
      "iter 5980 || Loss: 3.0102 ||timer: 0.0787 sec.\n",
      "iter 5990 || Loss: 1.9964 ||timer: 0.0770 sec.\n",
      "iter 6000 || Loss: 2.5645 ||Saving state, iter: 6000\n",
      "timer: 0.0794 sec.\n",
      "iter 6010 || Loss: 2.8524 ||timer: 0.0808 sec.\n",
      "iter 6020 || Loss: 1.5036 ||timer: 0.0766 sec.\n",
      "iter 6030 || Loss: 1.4125 ||timer: 0.0760 sec.\n",
      "iter 6040 || Loss: 5.3128 ||timer: 0.0800 sec.\n",
      "iter 6050 || Loss: 3.7648 ||timer: 0.0843 sec.\n",
      "iter 6060 || Loss: 1.3221 ||timer: 0.0807 sec.\n",
      "iter 6070 || Loss: 2.4387 ||timer: 0.0810 sec.\n",
      "iter 6080 || Loss: 5.3642 ||timer: 0.0796 sec.\n",
      "iter 6090 || Loss: 1.0741 ||timer: 0.0814 sec.\n",
      "iter 6100 || Loss: 2.4497 ||timer: 0.0767 sec.\n",
      "iter 6110 || Loss: 3.9762 ||timer: 0.0798 sec.\n",
      "iter 6120 || Loss: 2.7543 ||timer: 0.0873 sec.\n",
      "iter 6130 || Loss: 1.8817 ||timer: 0.0787 sec.\n",
      "iter 6140 || Loss: 1.7351 ||timer: 0.0841 sec.\n",
      "iter 6150 || Loss: 1.2749 ||timer: 0.0853 sec.\n",
      "iter 6160 || Loss: 3.1195 ||timer: 0.0838 sec.\n",
      "iter 6170 || Loss: 5.4072 ||timer: 0.0854 sec.\n",
      "iter 6180 || Loss: 2.3103 ||timer: 0.0782 sec.\n",
      "iter 6190 || Loss: 1.9230 ||timer: 0.0792 sec.\n",
      "iter 6200 || Loss: 1.7678 ||timer: 0.0836 sec.\n",
      "iter 6210 || Loss: 3.7854 ||timer: 0.0868 sec.\n",
      "iter 6220 || Loss: 2.6821 ||timer: 0.0986 sec.\n",
      "iter 6230 || Loss: 1.4234 ||timer: 0.0989 sec.\n",
      "iter 6240 || Loss: 3.3165 ||timer: 0.1017 sec.\n",
      "iter 6250 || Loss: 7.7055 ||timer: 0.0990 sec.\n",
      "iter 6260 || Loss: 4.6301 ||timer: 0.0944 sec.\n",
      "iter 6270 || Loss: 3.3056 ||timer: 0.0918 sec.\n",
      "iter 6280 || Loss: 6.5743 ||timer: 0.0989 sec.\n",
      "iter 6290 || Loss: 0.8894 ||timer: 0.0831 sec.\n",
      "iter 6300 || Loss: 4.4600 ||timer: 0.0776 sec.\n",
      "iter 6310 || Loss: 3.5021 ||timer: 0.1115 sec.\n",
      "iter 6320 || Loss: 3.5171 ||timer: 0.0822 sec.\n",
      "iter 6330 || Loss: 2.1285 ||timer: 0.0784 sec.\n",
      "iter 6340 || Loss: 3.5968 ||timer: 0.0769 sec.\n",
      "iter 6350 || Loss: 2.6709 ||timer: 0.0805 sec.\n",
      "iter 6360 || Loss: 4.2219 ||timer: 0.0768 sec.\n",
      "iter 6370 || Loss: 3.6670 ||timer: 0.0755 sec.\n",
      "iter 6380 || Loss: 3.8032 ||timer: 0.0807 sec.\n",
      "iter 6390 || Loss: 1.6790 ||timer: 0.0779 sec.\n",
      "iter 6400 || Loss: 4.8691 ||timer: 0.0758 sec.\n",
      "iter 6410 || Loss: 6.4394 ||timer: 0.0803 sec.\n",
      "iter 6420 || Loss: 1.8590 ||timer: 0.0770 sec.\n",
      "iter 6430 || Loss: 1.1155 ||timer: 0.0793 sec.\n",
      "iter 6440 || Loss: 5.1782 ||timer: 0.0765 sec.\n",
      "iter 6450 || Loss: 2.0926 ||timer: 0.0780 sec.\n",
      "iter 6460 || Loss: 1.2720 ||timer: 0.0815 sec.\n",
      "iter 6470 || Loss: 2.4946 ||timer: 0.0784 sec.\n",
      "iter 6480 || Loss: 2.4312 ||timer: 0.0792 sec.\n",
      "iter 6490 || Loss: 6.0868 ||timer: 0.0787 sec.\n",
      "iter 6500 || Loss: 3.8670 ||Saving state, iter: 6500\n",
      "timer: 0.0781 sec.\n",
      "iter 6510 || Loss: 3.3845 ||timer: 0.0762 sec.\n",
      "iter 6520 || Loss: 2.7717 ||timer: 0.0764 sec.\n",
      "iter 6530 || Loss: 4.7587 ||timer: 0.0758 sec.\n",
      "iter 6540 || Loss: 3.3460 ||timer: 0.0796 sec.\n",
      "iter 6550 || Loss: 5.1562 ||timer: 0.0805 sec.\n",
      "iter 6560 || Loss: 4.7136 ||timer: 0.0778 sec.\n",
      "iter 6570 || Loss: 2.8272 ||timer: 0.0766 sec.\n",
      "iter 6580 || Loss: 1.6458 ||timer: 0.0796 sec.\n",
      "iter 6590 || Loss: 2.7961 ||timer: 0.0768 sec.\n",
      "iter 6600 || Loss: 3.5455 ||timer: 0.0757 sec.\n",
      "iter 6610 || Loss: 1.4095 ||timer: 0.0781 sec.\n",
      "iter 6620 || Loss: 3.2134 ||timer: 0.0782 sec.\n",
      "iter 6630 || Loss: 3.5043 ||timer: 0.0755 sec.\n",
      "iter 6640 || Loss: 2.9575 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0768 sec.\n",
      "iter 6650 || Loss: 1.9145 ||timer: 0.0779 sec.\n",
      "iter 6660 || Loss: 1.7890 ||timer: 0.0788 sec.\n",
      "iter 6670 || Loss: 2.0411 ||timer: 0.0764 sec.\n",
      "iter 6680 || Loss: 1.8385 ||timer: 0.0797 sec.\n",
      "iter 6690 || Loss: 3.7850 ||timer: 0.0773 sec.\n",
      "iter 6700 || Loss: 2.4955 ||timer: 0.0767 sec.\n",
      "iter 6710 || Loss: 4.1455 ||timer: 0.0774 sec.\n",
      "iter 6720 || Loss: 2.9458 ||timer: 0.0758 sec.\n",
      "iter 6730 || Loss: 2.1500 ||timer: 0.0763 sec.\n",
      "iter 6740 || Loss: 4.1938 ||timer: 0.0767 sec.\n",
      "iter 6750 || Loss: 1.8319 ||timer: 0.0765 sec.\n",
      "iter 6760 || Loss: 2.2699 ||timer: 0.0770 sec.\n",
      "iter 6770 || Loss: 1.1581 ||timer: 0.0798 sec.\n",
      "iter 6780 || Loss: 4.9887 ||timer: 0.0760 sec.\n",
      "iter 6790 || Loss: 4.5512 ||timer: 0.0763 sec.\n",
      "iter 6800 || Loss: 2.0155 ||timer: 0.0772 sec.\n",
      "iter 6810 || Loss: 3.6269 ||timer: 0.0803 sec.\n",
      "iter 6820 || Loss: 2.4185 ||timer: 0.0796 sec.\n",
      "iter 6830 || Loss: 2.0074 ||timer: 0.0757 sec.\n",
      "iter 6840 || Loss: 1.9503 ||timer: 0.0769 sec.\n",
      "iter 6850 || Loss: 4.4546 ||timer: 0.0759 sec.\n",
      "iter 6860 || Loss: 3.2735 ||timer: 0.0799 sec.\n",
      "iter 6870 || Loss: 4.5294 ||timer: 0.0778 sec.\n",
      "iter 6880 || Loss: 5.1965 ||timer: 0.0757 sec.\n",
      "iter 6890 || Loss: 1.6512 ||timer: 0.0768 sec.\n",
      "iter 6900 || Loss: 3.0017 ||timer: 0.0771 sec.\n",
      "iter 6910 || Loss: 1.1291 ||timer: 0.0792 sec.\n",
      "iter 6920 || Loss: 4.4875 ||timer: 0.0792 sec.\n",
      "iter 6930 || Loss: 3.8634 ||timer: 0.0776 sec.\n",
      "iter 6940 || Loss: 3.3424 ||timer: 0.0763 sec.\n",
      "iter 6950 || Loss: 3.8554 ||timer: 0.0801 sec.\n",
      "iter 6960 || Loss: 2.0822 ||timer: 0.0759 sec.\n",
      "iter 6970 || Loss: 3.5855 ||timer: 0.0761 sec.\n",
      "iter 6980 || Loss: 3.3573 ||timer: 0.0776 sec.\n",
      "iter 6990 || Loss: 1.6891 ||timer: 0.0776 sec.\n",
      "iter 7000 || Loss: 1.6043 ||Saving state, iter: 7000\n",
      "timer: 0.0772 sec.\n",
      "iter 7010 || Loss: 2.6646 ||timer: 0.0800 sec.\n",
      "iter 7020 || Loss: 1.8353 ||timer: 0.0790 sec.\n",
      "iter 7030 || Loss: 3.3704 ||timer: 0.0794 sec.\n",
      "iter 7040 || Loss: 1.8360 ||timer: 0.0809 sec.\n",
      "iter 7050 || Loss: 2.1942 ||timer: 0.0806 sec.\n",
      "iter 7060 || Loss: 3.4193 ||timer: 0.0770 sec.\n",
      "iter 7070 || Loss: 3.4367 ||timer: 0.0758 sec.\n",
      "iter 7080 || Loss: 2.2979 ||timer: 0.0769 sec.\n",
      "iter 7090 || Loss: 2.8806 ||timer: 0.0795 sec.\n",
      "iter 7100 || Loss: 2.8824 ||timer: 0.0789 sec.\n",
      "iter 7110 || Loss: 2.5378 ||timer: 0.0764 sec.\n",
      "iter 7120 || Loss: 2.7529 ||timer: 0.0763 sec.\n",
      "iter 7130 || Loss: 2.9241 ||timer: 0.0810 sec.\n",
      "iter 7140 || Loss: 1.9942 ||timer: 0.0788 sec.\n",
      "iter 7150 || Loss: 2.9994 ||timer: 0.0813 sec.\n",
      "iter 7160 || Loss: 1.6310 ||timer: 0.0778 sec.\n",
      "iter 7170 || Loss: 2.6316 ||timer: 0.0779 sec.\n",
      "iter 7180 || Loss: 2.2046 ||timer: 0.0819 sec.\n",
      "iter 7190 || Loss: 1.9053 ||timer: 0.0772 sec.\n",
      "iter 7200 || Loss: 3.1700 ||timer: 0.0774 sec.\n",
      "iter 7210 || Loss: 3.8123 ||timer: 0.0778 sec.\n",
      "iter 7220 || Loss: 4.7328 ||timer: 0.0809 sec.\n",
      "iter 7230 || Loss: 2.6969 ||timer: 0.0803 sec.\n",
      "iter 7240 || Loss: 2.2010 ||timer: 0.0793 sec.\n",
      "iter 7250 || Loss: 3.1033 ||timer: 0.0817 sec.\n",
      "iter 7260 || Loss: 5.0970 ||timer: 0.0802 sec.\n",
      "iter 7270 || Loss: 2.2674 ||timer: 0.0846 sec.\n",
      "iter 7280 || Loss: 2.3230 ||timer: 0.0779 sec.\n",
      "iter 7290 || Loss: 2.3565 ||timer: 0.0763 sec.\n",
      "iter 7300 || Loss: 2.5948 ||timer: 0.0803 sec.\n",
      "iter 7310 || Loss: 4.3189 ||timer: 0.0764 sec.\n",
      "iter 7320 || Loss: 2.1483 ||timer: 0.0771 sec.\n",
      "iter 7330 || Loss: 3.7284 ||timer: 0.0829 sec.\n",
      "iter 7340 || Loss: 3.3547 ||timer: 0.0829 sec.\n",
      "iter 7350 || Loss: 2.5778 ||timer: 0.0778 sec.\n",
      "iter 7360 || Loss: 1.7325 ||timer: 0.0823 sec.\n",
      "iter 7370 || Loss: 2.6037 ||timer: 0.0781 sec.\n",
      "iter 7380 || Loss: 5.1723 ||timer: 0.0793 sec.\n",
      "iter 7390 || Loss: 1.5862 ||timer: 0.0761 sec.\n",
      "iter 7400 || Loss: 2.5907 ||timer: 0.0791 sec.\n",
      "iter 7410 || Loss: 2.4596 ||timer: 0.0804 sec.\n",
      "iter 7420 || Loss: 1.6090 ||timer: 0.0764 sec.\n",
      "iter 7430 || Loss: 5.1188 ||timer: 0.0784 sec.\n",
      "iter 7440 || Loss: 3.7380 ||timer: 0.0813 sec.\n",
      "iter 7450 || Loss: 3.2175 ||timer: 0.0759 sec.\n",
      "iter 7460 || Loss: 4.0317 ||timer: 0.0769 sec.\n",
      "iter 7470 || Loss: 9.4856 ||timer: 0.0770 sec.\n",
      "iter 7480 || Loss: 3.3266 ||timer: 0.0766 sec.\n",
      "iter 7490 || Loss: 5.1374 ||timer: 0.0776 sec.\n",
      "iter 7500 || Loss: 3.3142 ||Saving state, iter: 7500\n",
      "timer: 0.0765 sec.\n",
      "iter 7510 || Loss: 1.2477 ||timer: 0.0784 sec.\n",
      "iter 7520 || Loss: 2.5147 ||timer: 0.0775 sec.\n",
      "iter 7530 || Loss: 3.4244 ||timer: 0.0777 sec.\n",
      "iter 7540 || Loss: 4.8749 ||timer: 0.0777 sec.\n",
      "iter 7550 || Loss: 1.4138 ||timer: 0.0773 sec.\n",
      "iter 7560 || Loss: 3.3860 ||timer: 0.0757 sec.\n",
      "iter 7570 || Loss: 4.5151 ||timer: 0.0797 sec.\n",
      "iter 7580 || Loss: 1.8964 ||timer: 0.0770 sec.\n",
      "iter 7590 || Loss: 3.5764 ||timer: 0.0772 sec.\n",
      "iter 7600 || Loss: 1.1959 ||timer: 0.0763 sec.\n",
      "iter 7610 || Loss: 3.4690 ||timer: 0.0764 sec.\n",
      "iter 7620 || Loss: 4.3699 ||timer: 0.0760 sec.\n",
      "iter 7630 || Loss: 1.5924 ||timer: 0.0767 sec.\n",
      "iter 7640 || Loss: 3.0669 ||timer: 0.0804 sec.\n",
      "iter 7650 || Loss: 3.3240 ||timer: 0.0754 sec.\n",
      "iter 7660 || Loss: 3.1384 ||timer: 0.0761 sec.\n",
      "iter 7670 || Loss: 1.7473 ||timer: 0.0801 sec.\n",
      "iter 7680 || Loss: 2.3419 ||timer: 0.0755 sec.\n",
      "iter 7690 || Loss: 2.7126 ||timer: 0.0771 sec.\n",
      "iter 7700 || Loss: 3.4069 ||timer: 0.0875 sec.\n",
      "iter 7710 || Loss: 3.3364 ||timer: 0.0901 sec.\n",
      "iter 7720 || Loss: 2.7766 ||timer: 0.0801 sec.\n",
      "iter 7730 || Loss: 1.0095 ||timer: 0.0784 sec.\n",
      "iter 7740 || Loss: 2.7688 ||timer: 0.0759 sec.\n",
      "iter 7750 || Loss: 3.9028 ||timer: 0.0874 sec.\n",
      "iter 7760 || Loss: 1.9496 ||timer: 0.0802 sec.\n",
      "iter 7770 || Loss: 3.4661 ||timer: 0.0765 sec.\n",
      "iter 7780 || Loss: 2.6166 ||timer: 0.0783 sec.\n",
      "iter 7790 || Loss: 1.6061 ||timer: 0.0823 sec.\n",
      "iter 7800 || Loss: 4.3062 ||timer: 0.0789 sec.\n",
      "iter 7810 || Loss: 2.3709 ||timer: 0.0819 sec.\n",
      "iter 7820 || Loss: 3.9757 ||timer: 0.0807 sec.\n",
      "iter 7830 || Loss: 2.8536 ||timer: 0.0786 sec.\n",
      "iter 7840 || Loss: 1.6175 ||timer: 0.0779 sec.\n",
      "iter 7850 || Loss: 3.1830 ||timer: 0.0813 sec.\n",
      "iter 7860 || Loss: 4.5137 ||timer: 0.0798 sec.\n",
      "iter 7870 || Loss: 2.3399 ||timer: 0.0779 sec.\n",
      "iter 7880 || Loss: 2.6117 ||timer: 0.0777 sec.\n",
      "iter 7890 || Loss: 1.8250 ||timer: 0.0801 sec.\n",
      "iter 7900 || Loss: 1.6439 ||timer: 0.0765 sec.\n",
      "iter 7910 || Loss: 1.8552 ||timer: 0.0788 sec.\n",
      "iter 7920 || Loss: 2.1976 ||timer: 0.0755 sec.\n",
      "iter 7930 || Loss: 1.3114 ||timer: 0.0812 sec.\n",
      "iter 7940 || Loss: 2.0405 ||timer: 0.0793 sec.\n",
      "iter 7950 || Loss: 3.7465 ||timer: 0.0837 sec.\n",
      "iter 7960 || Loss: 1.7567 ||timer: 0.0759 sec.\n",
      "iter 7970 || Loss: 2.7621 ||timer: 0.0775 sec.\n",
      "iter 7980 || Loss: 4.1635 ||timer: 0.0848 sec.\n",
      "iter 7990 || Loss: 1.2314 ||Change learning rate to:  1.0000000000000003e-05\n",
      "timer: 0.0891 sec.\n",
      "iter 8000 || Loss: 5.9649 ||Saving state, iter: 8000\n",
      "timer: 0.0805 sec.\n",
      "iter 8010 || Loss: 3.3550 ||timer: 0.0820 sec.\n",
      "iter 8020 || Loss: 2.8552 ||timer: 0.0797 sec.\n",
      "iter 8030 || Loss: 1.9595 ||timer: 0.0858 sec.\n",
      "iter 8040 || Loss: 0.9956 ||timer: 0.0903 sec.\n",
      "iter 8050 || Loss: 1.8453 ||timer: 0.0860 sec.\n",
      "iter 8060 || Loss: 2.0615 ||timer: 0.0842 sec.\n",
      "iter 8070 || Loss: 2.2904 ||timer: 0.0861 sec.\n",
      "iter 8080 || Loss: 4.3881 ||timer: 0.0835 sec.\n",
      "iter 8090 || Loss: 2.7835 ||timer: 0.0880 sec.\n",
      "iter 8100 || Loss: 4.8740 ||timer: 0.0832 sec.\n",
      "iter 8110 || Loss: 5.1731 ||timer: 0.0983 sec.\n",
      "iter 8120 || Loss: 5.6053 ||timer: 0.0887 sec.\n",
      "iter 8130 || Loss: 2.1538 ||timer: 0.0779 sec.\n",
      "iter 8140 || Loss: 3.2081 ||timer: 0.0913 sec.\n",
      "iter 8150 || Loss: 2.0551 ||timer: 0.0830 sec.\n",
      "iter 8160 || Loss: 2.2483 ||timer: 0.0866 sec.\n",
      "iter 8170 || Loss: 1.5696 ||timer: 0.0844 sec.\n",
      "iter 8180 || Loss: 1.5596 ||timer: 0.0788 sec.\n",
      "iter 8190 || Loss: 1.9999 ||timer: 0.0799 sec.\n",
      "iter 8200 || Loss: 1.7112 ||timer: 0.0869 sec.\n",
      "iter 8210 || Loss: 2.0227 ||timer: 0.0763 sec.\n",
      "iter 8220 || Loss: 1.6955 ||timer: 0.0825 sec.\n",
      "iter 8230 || Loss: 3.0441 ||timer: 0.0775 sec.\n",
      "iter 8240 || Loss: 2.3513 ||timer: 0.0823 sec.\n",
      "iter 8250 || Loss: 1.4970 ||timer: 0.0799 sec.\n",
      "iter 8260 || Loss: 1.6205 ||timer: 0.0843 sec.\n",
      "iter 8270 || Loss: 1.9897 ||timer: 0.0776 sec.\n",
      "iter 8280 || Loss: 3.8560 ||timer: 0.0800 sec.\n",
      "iter 8290 || Loss: 3.0010 ||timer: 0.0806 sec.\n",
      "iter 8300 || Loss: 1.7077 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0771 sec.\n",
      "iter 8310 || Loss: 3.8204 ||timer: 0.0797 sec.\n",
      "iter 8320 || Loss: 3.1554 ||timer: 0.0789 sec.\n",
      "iter 8330 || Loss: 1.8673 ||timer: 0.0764 sec.\n",
      "iter 8340 || Loss: 1.1355 ||timer: 0.0902 sec.\n",
      "iter 8350 || Loss: 5.2660 ||timer: 0.0849 sec.\n",
      "iter 8360 || Loss: 2.2426 ||timer: 0.0877 sec.\n",
      "iter 8370 || Loss: 1.8351 ||timer: 0.0890 sec.\n",
      "iter 8380 || Loss: 2.1766 ||timer: 0.0864 sec.\n",
      "iter 8390 || Loss: 3.0807 ||timer: 0.0907 sec.\n",
      "iter 8400 || Loss: 3.8048 ||timer: 0.0900 sec.\n",
      "iter 8410 || Loss: 2.7440 ||timer: 0.0918 sec.\n",
      "iter 8420 || Loss: 2.7854 ||timer: 0.0826 sec.\n",
      "iter 8430 || Loss: 2.7978 ||timer: 0.0792 sec.\n",
      "iter 8440 || Loss: 1.2076 ||timer: 0.0818 sec.\n",
      "iter 8450 || Loss: 1.7227 ||timer: 0.0793 sec.\n",
      "iter 8460 || Loss: 1.2583 ||timer: 0.0825 sec.\n",
      "iter 8470 || Loss: 1.2772 ||timer: 0.0800 sec.\n",
      "iter 8480 || Loss: 1.2164 ||timer: 0.0805 sec.\n",
      "iter 8490 || Loss: 4.4423 ||timer: 0.0771 sec.\n",
      "iter 8500 || Loss: 1.7368 ||Saving state, iter: 8500\n",
      "timer: 0.0774 sec.\n",
      "iter 8510 || Loss: 2.2475 ||timer: 0.0791 sec.\n",
      "iter 8520 || Loss: 1.3062 ||timer: 0.0808 sec.\n",
      "iter 8530 || Loss: 4.2690 ||timer: 0.0766 sec.\n",
      "iter 8540 || Loss: 2.7865 ||timer: 0.0817 sec.\n",
      "iter 8550 || Loss: 2.1193 ||timer: 0.0829 sec.\n",
      "iter 8560 || Loss: 1.3566 ||timer: 0.0825 sec.\n",
      "iter 8570 || Loss: 5.0817 ||timer: 0.0882 sec.\n",
      "iter 8580 || Loss: 1.5914 ||timer: 0.0895 sec.\n",
      "iter 8590 || Loss: 2.7075 ||timer: 0.0925 sec.\n",
      "iter 8600 || Loss: 6.0935 ||timer: 0.0887 sec.\n",
      "iter 8610 || Loss: 2.1265 ||timer: 0.0832 sec.\n",
      "iter 8620 || Loss: 3.4847 ||timer: 0.0849 sec.\n",
      "iter 8630 || Loss: 1.8988 ||timer: 0.0844 sec.\n",
      "iter 8640 || Loss: 2.4432 ||timer: 0.0804 sec.\n",
      "iter 8650 || Loss: 1.6315 ||timer: 0.0873 sec.\n",
      "iter 8660 || Loss: 1.1781 ||timer: 0.0848 sec.\n",
      "iter 8670 || Loss: 1.3153 ||timer: 0.0852 sec.\n",
      "iter 8680 || Loss: 1.6960 ||timer: 0.0835 sec.\n",
      "iter 8690 || Loss: 2.3362 ||timer: 0.0806 sec.\n",
      "iter 8700 || Loss: 3.1362 ||timer: 0.0872 sec.\n",
      "iter 8710 || Loss: 1.9489 ||timer: 0.0851 sec.\n",
      "iter 8720 || Loss: 3.0141 ||timer: 0.0854 sec.\n",
      "iter 8730 || Loss: 2.3539 ||timer: 0.0790 sec.\n",
      "iter 8740 || Loss: 2.0184 ||timer: 0.0779 sec.\n",
      "iter 8750 || Loss: 2.5223 ||timer: 0.0874 sec.\n",
      "iter 8760 || Loss: 1.0491 ||timer: 0.0914 sec.\n",
      "iter 8770 || Loss: 1.2578 ||timer: 0.0804 sec.\n",
      "iter 8780 || Loss: 2.2999 ||timer: 0.0759 sec.\n",
      "iter 8790 || Loss: 4.1291 ||timer: 0.0829 sec.\n",
      "iter 8800 || Loss: 1.5177 ||timer: 0.0863 sec.\n",
      "iter 8810 || Loss: 2.9447 ||timer: 0.0852 sec.\n",
      "iter 8820 || Loss: 2.4995 ||timer: 0.0860 sec.\n",
      "iter 8830 || Loss: 1.6485 ||timer: 0.0852 sec.\n",
      "iter 8840 || Loss: 3.5044 ||timer: 0.0863 sec.\n",
      "iter 8850 || Loss: 3.0885 ||timer: 0.0814 sec.\n",
      "iter 8860 || Loss: 1.6883 ||timer: 0.0797 sec.\n",
      "iter 8870 || Loss: 4.5003 ||timer: 0.0836 sec.\n",
      "iter 8880 || Loss: 2.1837 ||timer: 0.0783 sec.\n",
      "iter 8890 || Loss: 3.4851 ||timer: 0.0776 sec.\n",
      "iter 8900 || Loss: 1.4328 ||timer: 0.0797 sec.\n",
      "iter 8910 || Loss: 2.3637 ||timer: 0.0799 sec.\n",
      "iter 8920 || Loss: 2.2351 ||timer: 0.0774 sec.\n",
      "iter 8930 || Loss: 2.9051 ||timer: 0.0772 sec.\n",
      "iter 8940 || Loss: 2.1043 ||timer: 0.0802 sec.\n",
      "iter 8950 || Loss: 4.3488 ||timer: 0.0801 sec.\n",
      "iter 8960 || Loss: 2.6075 ||timer: 0.0769 sec.\n",
      "iter 8970 || Loss: 2.1580 ||timer: 0.0801 sec.\n",
      "iter 8980 || Loss: 1.9448 ||timer: 0.0779 sec.\n",
      "iter 8990 || Loss: 1.6718 ||timer: 0.0793 sec.\n",
      "iter 9000 || Loss: 2.5790 ||Saving state, iter: 9000\n",
      "timer: 0.0802 sec.\n",
      "iter 9010 || Loss: 3.0278 ||timer: 0.0808 sec.\n",
      "iter 9020 || Loss: 7.9975 ||timer: 0.0787 sec.\n",
      "iter 9030 || Loss: 2.2387 ||timer: 0.0775 sec.\n",
      "iter 9040 || Loss: 4.5986 ||timer: 0.0780 sec.\n",
      "iter 9050 || Loss: 4.3240 ||timer: 0.0802 sec.\n",
      "iter 9060 || Loss: 2.6035 ||timer: 0.0762 sec.\n",
      "iter 9070 || Loss: 2.4327 ||timer: 0.0783 sec.\n",
      "iter 9080 || Loss: 3.2321 ||timer: 0.0771 sec.\n",
      "iter 9090 || Loss: 2.8375 ||timer: 0.0844 sec.\n",
      "iter 9100 || Loss: 1.7147 ||timer: 0.0824 sec.\n",
      "iter 9110 || Loss: 3.8618 ||timer: 0.0858 sec.\n",
      "iter 9120 || Loss: 2.6875 ||timer: 0.0852 sec.\n",
      "iter 9130 || Loss: 1.5653 ||timer: 0.0862 sec.\n",
      "iter 9140 || Loss: 3.8440 ||timer: 0.0914 sec.\n",
      "iter 9150 || Loss: 2.0215 ||timer: 0.0816 sec.\n",
      "iter 9160 || Loss: 1.5382 ||timer: 0.0881 sec.\n",
      "iter 9170 || Loss: 2.1429 ||timer: 0.0938 sec.\n",
      "iter 9180 || Loss: 7.9690 ||timer: 0.0839 sec.\n",
      "iter 9190 || Loss: 1.8010 ||timer: 0.0776 sec.\n",
      "iter 9200 || Loss: 4.1758 ||timer: 0.0811 sec.\n",
      "iter 9210 || Loss: 2.4208 ||timer: 0.0759 sec.\n",
      "iter 9220 || Loss: 1.6200 ||timer: 0.0813 sec.\n",
      "iter 9230 || Loss: 1.1702 ||timer: 0.0784 sec.\n",
      "iter 9240 || Loss: 3.5552 ||timer: 0.0821 sec.\n",
      "iter 9250 || Loss: 3.3257 ||timer: 0.0792 sec.\n",
      "iter 9260 || Loss: 2.5357 ||timer: 0.0779 sec.\n",
      "iter 9270 || Loss: 2.6105 ||timer: 0.0775 sec.\n",
      "iter 9280 || Loss: 1.1688 ||timer: 0.0783 sec.\n",
      "iter 9290 || Loss: 2.4924 ||timer: 0.0768 sec.\n",
      "iter 9300 || Loss: 1.7576 ||timer: 0.0815 sec.\n",
      "iter 9310 || Loss: 1.7830 ||timer: 0.0784 sec.\n",
      "iter 9320 || Loss: 3.1991 ||timer: 0.0772 sec.\n",
      "iter 9330 || Loss: 2.0061 ||timer: 0.0756 sec.\n",
      "iter 9340 || Loss: 3.7356 ||timer: 0.0816 sec.\n",
      "iter 9350 || Loss: 1.6705 ||timer: 0.0793 sec.\n",
      "iter 9360 || Loss: 3.3418 ||timer: 0.0768 sec.\n",
      "iter 9370 || Loss: 3.4166 ||timer: 0.0766 sec.\n",
      "iter 9380 || Loss: 4.0070 ||timer: 0.0781 sec.\n",
      "iter 9390 || Loss: 0.9003 ||timer: 0.0771 sec.\n",
      "iter 9400 || Loss: 1.2420 ||timer: 0.0795 sec.\n",
      "iter 9410 || Loss: 3.3421 ||timer: 0.0793 sec.\n",
      "iter 9420 || Loss: 2.0196 ||timer: 0.0771 sec.\n",
      "iter 9430 || Loss: 2.8299 ||timer: 0.0778 sec.\n",
      "iter 9440 || Loss: 1.7902 ||timer: 0.0772 sec.\n",
      "iter 9450 || Loss: 4.1277 ||timer: 0.0771 sec.\n",
      "iter 9460 || Loss: 0.9876 ||timer: 0.0780 sec.\n",
      "iter 9470 || Loss: 4.4683 ||timer: 0.0772 sec.\n",
      "iter 9480 || Loss: 1.3164 ||timer: 0.0770 sec.\n",
      "iter 9490 || Loss: 2.3195 ||timer: 0.0792 sec.\n",
      "iter 9500 || Loss: 3.3175 ||Saving state, iter: 9500\n",
      "timer: 0.0807 sec.\n",
      "iter 9510 || Loss: 3.0789 ||timer: 0.0764 sec.\n",
      "iter 9520 || Loss: 2.7681 ||timer: 0.0800 sec.\n",
      "iter 9530 || Loss: 2.3235 ||timer: 0.0816 sec.\n",
      "iter 9540 || Loss: 3.5426 ||timer: 0.0775 sec.\n",
      "iter 9550 || Loss: 1.2325 ||timer: 0.0806 sec.\n",
      "iter 9560 || Loss: 1.6332 ||timer: 0.0787 sec.\n",
      "iter 9570 || Loss: 3.4465 ||timer: 0.0771 sec.\n",
      "iter 9580 || Loss: 1.6548 ||timer: 0.0756 sec.\n",
      "iter 9590 || Loss: 3.7112 ||timer: 0.0782 sec.\n",
      "iter 9600 || Loss: 5.1596 ||timer: 0.0803 sec.\n",
      "iter 9610 || Loss: 2.1909 ||timer: 0.0772 sec.\n",
      "iter 9620 || Loss: 2.6815 ||timer: 0.0768 sec.\n",
      "iter 9630 || Loss: 2.4850 ||timer: 0.0792 sec.\n",
      "iter 9640 || Loss: 1.6416 ||timer: 0.0803 sec.\n",
      "iter 9650 || Loss: 2.1894 ||timer: 0.0792 sec.\n",
      "iter 9660 || Loss: 2.1642 ||timer: 0.0791 sec.\n",
      "iter 9670 || Loss: 2.1001 ||timer: 0.0764 sec.\n",
      "iter 9680 || Loss: 3.6052 ||timer: 0.0807 sec.\n",
      "iter 9690 || Loss: 2.6669 ||timer: 0.0792 sec.\n",
      "iter 9700 || Loss: 4.6005 ||timer: 0.0775 sec.\n",
      "iter 9710 || Loss: 2.0243 ||timer: 0.0772 sec.\n",
      "iter 9720 || Loss: 6.6079 ||timer: 0.0802 sec.\n",
      "iter 9730 || Loss: 5.2255 ||timer: 0.0773 sec.\n",
      "iter 9740 || Loss: 1.8661 ||timer: 0.0775 sec.\n",
      "iter 9750 || Loss: 2.3369 ||timer: 0.0782 sec.\n",
      "iter 9760 || Loss: 2.5784 ||timer: 0.0767 sec.\n",
      "iter 9770 || Loss: 2.3297 ||timer: 0.0780 sec.\n",
      "iter 9780 || Loss: 3.8662 ||timer: 0.0815 sec.\n",
      "iter 9790 || Loss: 2.1723 ||timer: 0.0807 sec.\n",
      "iter 9800 || Loss: 2.9238 ||timer: 0.0771 sec.\n",
      "iter 9810 || Loss: 1.7426 ||timer: 0.0774 sec.\n",
      "iter 9820 || Loss: 2.3217 ||timer: 0.0764 sec.\n",
      "iter 9830 || Loss: 1.8196 ||timer: 0.0805 sec.\n",
      "iter 9840 || Loss: 3.8238 ||timer: 0.0791 sec.\n",
      "iter 9850 || Loss: 5.4187 ||timer: 0.0781 sec.\n",
      "iter 9860 || Loss: 3.2861 ||timer: 0.0795 sec.\n",
      "iter 9870 || Loss: 2.6122 ||timer: 0.0790 sec.\n",
      "iter 9880 || Loss: 2.9922 ||timer: 0.0803 sec.\n",
      "iter 9890 || Loss: 4.2950 ||timer: 0.0768 sec.\n",
      "iter 9900 || Loss: 2.8490 ||timer: 0.0768 sec.\n",
      "iter 9910 || Loss: 2.2519 ||timer: 0.0798 sec.\n",
      "iter 9920 || Loss: 1.8364 ||timer: 0.0780 sec.\n",
      "iter 9930 || Loss: 2.3819 ||timer: 0.0778 sec.\n",
      "iter 9940 || Loss: 5.0790 ||timer: 0.0797 sec.\n",
      "iter 9950 || Loss: 1.6802 ||timer: 0.0750 sec.\n",
      "iter 9960 || Loss: 1.6460 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0768 sec.\n",
      "iter 9970 || Loss: 2.2268 ||timer: 0.0785 sec.\n",
      "iter 9980 || Loss: 0.9144 ||timer: 0.0763 sec.\n",
      "iter 9990 || Loss: 2.2555 ||timer: 0.0804 sec.\n",
      "iter 10000 || Loss: 4.2239 ||Saving state, iter: 10000\n",
      "timer: 0.0777 sec.\n",
      "iter 10010 || Loss: 1.8649 ||timer: 0.0797 sec.\n",
      "iter 10020 || Loss: 1.7482 ||timer: 0.0785 sec.\n",
      "iter 10030 || Loss: 1.5694 ||timer: 0.0754 sec.\n",
      "iter 10040 || Loss: 3.0462 ||timer: 0.0848 sec.\n",
      "iter 10050 || Loss: 3.0045 ||timer: 0.0779 sec.\n",
      "iter 10060 || Loss: 3.6469 ||timer: 0.0769 sec.\n",
      "iter 10070 || Loss: 4.8311 ||timer: 0.0785 sec.\n",
      "iter 10080 || Loss: 2.3758 ||timer: 0.0764 sec.\n",
      "iter 10090 || Loss: 4.2799 ||timer: 0.0779 sec.\n",
      "iter 10100 || Loss: 2.3092 ||timer: 0.0781 sec.\n",
      "iter 10110 || Loss: 4.5776 ||timer: 0.0786 sec.\n",
      "iter 10120 || Loss: 3.4997 ||timer: 0.0770 sec.\n",
      "iter 10130 || Loss: 3.1328 ||timer: 0.0775 sec.\n",
      "iter 10140 || Loss: 1.3489 ||timer: 0.0804 sec.\n",
      "iter 10150 || Loss: 2.7149 ||timer: 0.0795 sec.\n",
      "iter 10160 || Loss: 4.1502 ||timer: 0.0766 sec.\n",
      "iter 10170 || Loss: 3.3847 ||timer: 0.0857 sec.\n",
      "iter 10180 || Loss: 6.1646 ||timer: 0.0793 sec.\n",
      "iter 10190 || Loss: 2.6257 ||timer: 0.0773 sec.\n",
      "iter 10200 || Loss: 2.9716 ||timer: 0.0769 sec.\n",
      "iter 10210 || Loss: 2.0003 ||timer: 0.0771 sec.\n",
      "iter 10220 || Loss: 2.0215 ||timer: 0.0775 sec.\n",
      "iter 10230 || Loss: 2.1668 ||timer: 0.0785 sec.\n",
      "iter 10240 || Loss: 2.3920 ||timer: 0.0788 sec.\n",
      "iter 10250 || Loss: 2.6331 ||timer: 0.0781 sec.\n",
      "iter 10260 || Loss: 3.2272 ||timer: 0.0814 sec.\n",
      "iter 10270 || Loss: 3.0825 ||timer: 0.0781 sec.\n",
      "iter 10280 || Loss: 3.7316 ||timer: 0.0794 sec.\n",
      "iter 10290 || Loss: 4.1437 ||timer: 0.0757 sec.\n",
      "iter 10300 || Loss: 1.3383 ||timer: 0.0779 sec.\n",
      "iter 10310 || Loss: 1.7079 ||timer: 0.0772 sec.\n",
      "iter 10320 || Loss: 2.2741 ||timer: 0.0772 sec.\n",
      "iter 10330 || Loss: 1.2597 ||timer: 0.0766 sec.\n",
      "iter 10340 || Loss: 4.3111 ||timer: 0.0780 sec.\n",
      "iter 10350 || Loss: 2.7188 ||timer: 0.0786 sec.\n",
      "iter 10360 || Loss: 2.6447 ||timer: 0.0800 sec.\n",
      "iter 10370 || Loss: 1.9235 ||timer: 0.0789 sec.\n",
      "iter 10380 || Loss: 1.8638 ||timer: 0.0785 sec.\n",
      "iter 10390 || Loss: 2.5832 ||timer: 0.0807 sec.\n",
      "iter 10400 || Loss: 3.9864 ||timer: 0.0774 sec.\n",
      "iter 10410 || Loss: 2.2831 ||timer: 0.0795 sec.\n",
      "iter 10420 || Loss: 3.4795 ||timer: 0.0783 sec.\n",
      "iter 10430 || Loss: 3.7005 ||timer: 0.0780 sec.\n",
      "iter 10440 || Loss: 4.8731 ||timer: 0.0816 sec.\n",
      "iter 10450 || Loss: 2.8984 ||timer: 0.0763 sec.\n",
      "iter 10460 || Loss: 3.0070 ||timer: 0.0806 sec.\n",
      "iter 10470 || Loss: 4.0167 ||timer: 0.0762 sec.\n",
      "iter 10480 || Loss: 4.8455 ||timer: 0.0772 sec.\n",
      "iter 10490 || Loss: 2.2926 ||timer: 0.0783 sec.\n",
      "iter 10500 || Loss: 2.2205 ||Saving state, iter: 10500\n",
      "timer: 0.0791 sec.\n",
      "iter 10510 || Loss: 2.2489 ||timer: 0.0799 sec.\n",
      "iter 10520 || Loss: 2.7190 ||timer: 0.0766 sec.\n",
      "iter 10530 || Loss: 2.6438 ||timer: 0.0851 sec.\n",
      "iter 10540 || Loss: 2.0552 ||timer: 0.0810 sec.\n",
      "iter 10550 || Loss: 3.9157 ||timer: 0.0768 sec.\n",
      "iter 10560 || Loss: 1.1613 ||timer: 0.0765 sec.\n",
      "iter 10570 || Loss: 1.1656 ||timer: 0.0759 sec.\n",
      "iter 10580 || Loss: 4.5363 ||timer: 0.0802 sec.\n",
      "iter 10590 || Loss: 2.5386 ||timer: 0.0779 sec.\n",
      "iter 10600 || Loss: 3.1198 ||timer: 0.0790 sec.\n",
      "iter 10610 || Loss: 1.8138 ||timer: 0.0763 sec.\n",
      "iter 10620 || Loss: 1.3339 ||timer: 0.0772 sec.\n",
      "iter 10630 || Loss: 1.6468 ||timer: 0.0779 sec.\n",
      "iter 10640 || Loss: 1.2805 ||timer: 0.0777 sec.\n",
      "iter 10650 || Loss: 2.2451 ||timer: 0.0778 sec.\n",
      "iter 10660 || Loss: 1.4554 ||timer: 0.0852 sec.\n",
      "iter 10670 || Loss: 1.9845 ||timer: 0.0807 sec.\n",
      "iter 10680 || Loss: 2.3623 ||timer: 0.0783 sec.\n",
      "iter 10690 || Loss: 1.5101 ||timer: 0.0762 sec.\n",
      "iter 10700 || Loss: 2.9057 ||timer: 0.0798 sec.\n",
      "iter 10710 || Loss: 2.5865 ||timer: 0.0776 sec.\n",
      "iter 10720 || Loss: 2.3550 ||timer: 0.0797 sec.\n",
      "iter 10730 || Loss: 4.1988 ||timer: 0.0776 sec.\n",
      "iter 10740 || Loss: 0.8812 ||timer: 0.0821 sec.\n",
      "iter 10750 || Loss: 1.6187 ||timer: 0.0803 sec.\n",
      "iter 10760 || Loss: 1.5338 ||timer: 0.0767 sec.\n",
      "iter 10770 || Loss: 1.7148 ||timer: 0.0799 sec.\n",
      "iter 10780 || Loss: 1.6884 ||timer: 0.0765 sec.\n",
      "iter 10790 || Loss: 2.7173 ||timer: 0.0797 sec.\n",
      "iter 10800 || Loss: 2.3957 ||timer: 0.0819 sec.\n",
      "iter 10810 || Loss: 2.4368 ||timer: 0.0770 sec.\n",
      "iter 10820 || Loss: 0.9568 ||timer: 0.0811 sec.\n",
      "iter 10830 || Loss: 3.3288 ||timer: 0.0811 sec.\n",
      "iter 10840 || Loss: 2.0326 ||timer: 0.0776 sec.\n",
      "iter 10850 || Loss: 2.1418 ||timer: 0.0774 sec.\n",
      "iter 10860 || Loss: 0.7890 ||timer: 0.0764 sec.\n",
      "iter 10870 || Loss: 2.4051 ||timer: 0.0771 sec.\n",
      "iter 10880 || Loss: 1.5793 ||timer: 0.0812 sec.\n",
      "iter 10890 || Loss: 1.7753 ||timer: 0.0793 sec.\n",
      "iter 10900 || Loss: 3.8662 ||timer: 0.0806 sec.\n",
      "iter 10910 || Loss: 3.7388 ||timer: 0.0776 sec.\n",
      "iter 10920 || Loss: 3.8291 ||timer: 0.0803 sec.\n",
      "iter 10930 || Loss: 1.6893 ||timer: 0.0776 sec.\n",
      "iter 10940 || Loss: 1.1407 ||timer: 0.0766 sec.\n",
      "iter 10950 || Loss: 6.8852 ||timer: 0.0759 sec.\n",
      "iter 10960 || Loss: 1.9799 ||timer: 0.0788 sec.\n",
      "iter 10970 || Loss: 2.4081 ||timer: 0.0814 sec.\n",
      "iter 10980 || Loss: 1.3336 ||timer: 0.0778 sec.\n",
      "iter 10990 || Loss: 1.7896 ||timer: 0.0801 sec.\n",
      "iter 11000 || Loss: 5.2627 ||Saving state, iter: 11000\n",
      "timer: 0.0781 sec.\n",
      "iter 11010 || Loss: 2.5217 ||timer: 0.0777 sec.\n",
      "iter 11020 || Loss: 3.2401 ||timer: 0.0766 sec.\n",
      "iter 11030 || Loss: 1.6217 ||timer: 0.0771 sec.\n",
      "iter 11040 || Loss: 4.4088 ||timer: 0.0763 sec.\n",
      "iter 11050 || Loss: 1.8902 ||timer: 0.0762 sec.\n",
      "iter 11060 || Loss: 3.4167 ||timer: 0.0772 sec.\n",
      "iter 11070 || Loss: 1.8787 ||timer: 0.0811 sec.\n",
      "iter 11080 || Loss: 5.0007 ||timer: 0.0755 sec.\n",
      "iter 11090 || Loss: 2.6036 ||timer: 0.0791 sec.\n",
      "iter 11100 || Loss: 1.1724 ||timer: 0.0815 sec.\n",
      "iter 11110 || Loss: 1.9997 ||timer: 0.0769 sec.\n",
      "iter 11120 || Loss: 4.2217 ||timer: 0.0767 sec.\n",
      "iter 11130 || Loss: 1.6508 ||timer: 0.0770 sec.\n",
      "iter 11140 || Loss: 2.1716 ||timer: 0.0783 sec.\n",
      "iter 11150 || Loss: 4.9909 ||timer: 0.0782 sec.\n",
      "iter 11160 || Loss: 1.5076 ||timer: 0.0813 sec.\n",
      "iter 11170 || Loss: 2.8511 ||timer: 0.0789 sec.\n",
      "iter 11180 || Loss: 2.9152 ||timer: 0.0767 sec.\n",
      "iter 11190 || Loss: 2.1984 ||timer: 0.0759 sec.\n",
      "iter 11200 || Loss: 2.3350 ||timer: 0.0763 sec.\n",
      "iter 11210 || Loss: 1.9795 ||timer: 0.0793 sec.\n",
      "iter 11220 || Loss: 5.2432 ||timer: 0.0796 sec.\n",
      "iter 11230 || Loss: 3.0385 ||timer: 0.0769 sec.\n",
      "iter 11240 || Loss: 2.3150 ||timer: 0.0773 sec.\n",
      "iter 11250 || Loss: 1.9431 ||timer: 0.0765 sec.\n",
      "iter 11260 || Loss: 4.5936 ||timer: 0.0814 sec.\n",
      "iter 11270 || Loss: 2.8786 ||timer: 0.0808 sec.\n",
      "iter 11280 || Loss: 1.4944 ||timer: 0.0800 sec.\n",
      "iter 11290 || Loss: 2.1880 ||timer: 0.0770 sec.\n",
      "iter 11300 || Loss: 1.8727 ||timer: 0.0798 sec.\n",
      "iter 11310 || Loss: 1.7487 ||timer: 0.0770 sec.\n",
      "iter 11320 || Loss: 3.6125 ||timer: 0.0803 sec.\n",
      "iter 11330 || Loss: 1.3825 ||timer: 0.0776 sec.\n",
      "iter 11340 || Loss: 2.6562 ||timer: 0.0764 sec.\n",
      "iter 11350 || Loss: 2.0405 ||timer: 0.0812 sec.\n",
      "iter 11360 || Loss: 1.6161 ||timer: 0.0759 sec.\n",
      "iter 11370 || Loss: 2.1749 ||timer: 0.0767 sec.\n",
      "iter 11380 || Loss: 2.0725 ||timer: 0.0805 sec.\n",
      "iter 11390 || Loss: 1.5139 ||timer: 0.0783 sec.\n",
      "iter 11400 || Loss: 2.0379 ||timer: 0.0771 sec.\n",
      "iter 11410 || Loss: 4.0875 ||timer: 0.0797 sec.\n",
      "iter 11420 || Loss: 3.3058 ||timer: 0.0806 sec.\n",
      "iter 11430 || Loss: 2.2523 ||timer: 0.0759 sec.\n",
      "iter 11440 || Loss: 1.6776 ||timer: 0.0764 sec.\n",
      "iter 11450 || Loss: 2.0745 ||timer: 0.0785 sec.\n",
      "iter 11460 || Loss: 1.3547 ||timer: 0.0781 sec.\n",
      "iter 11470 || Loss: 1.4921 ||timer: 0.0800 sec.\n",
      "iter 11480 || Loss: 4.7519 ||timer: 0.0798 sec.\n",
      "iter 11490 || Loss: 4.0731 ||timer: 0.0775 sec.\n",
      "iter 11500 || Loss: 1.1274 ||Saving state, iter: 11500\n",
      "timer: 0.0775 sec.\n",
      "iter 11510 || Loss: 2.7607 ||timer: 0.0776 sec.\n",
      "iter 11520 || Loss: 2.8915 ||timer: 0.0795 sec.\n",
      "iter 11530 || Loss: 2.0949 ||timer: 0.0794 sec.\n",
      "iter 11540 || Loss: 4.8990 ||timer: 0.0772 sec.\n",
      "iter 11550 || Loss: 1.7358 ||timer: 0.0777 sec.\n",
      "iter 11560 || Loss: 1.8836 ||timer: 0.0782 sec.\n",
      "iter 11570 || Loss: 1.1707 ||timer: 0.0795 sec.\n",
      "iter 11580 || Loss: 2.4702 ||timer: 0.0828 sec.\n",
      "iter 11590 || Loss: 4.6301 ||timer: 0.0795 sec.\n",
      "iter 11600 || Loss: 1.8123 ||timer: 0.0805 sec.\n",
      "iter 11610 || Loss: 2.5454 ||timer: 0.0780 sec.\n",
      "iter 11620 || Loss: 4.1980 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0771 sec.\n",
      "iter 11630 || Loss: 2.5561 ||timer: 0.0801 sec.\n",
      "iter 11640 || Loss: 1.5226 ||timer: 0.0763 sec.\n",
      "iter 11650 || Loss: 2.6904 ||timer: 0.0799 sec.\n",
      "iter 11660 || Loss: 3.1283 ||timer: 0.0771 sec.\n",
      "iter 11670 || Loss: 1.0787 ||timer: 0.0784 sec.\n",
      "iter 11680 || Loss: 2.1166 ||timer: 0.0761 sec.\n",
      "iter 11690 || Loss: 1.1030 ||timer: 0.0804 sec.\n",
      "iter 11700 || Loss: 1.7350 ||timer: 0.0809 sec.\n",
      "iter 11710 || Loss: 3.1266 ||timer: 0.0774 sec.\n",
      "iter 11720 || Loss: 3.5543 ||timer: 0.0798 sec.\n",
      "iter 11730 || Loss: 1.5957 ||timer: 0.0771 sec.\n",
      "iter 11740 || Loss: 1.9276 ||timer: 0.0788 sec.\n",
      "iter 11750 || Loss: 1.7547 ||timer: 0.0791 sec.\n",
      "iter 11760 || Loss: 2.0279 ||timer: 0.0798 sec.\n",
      "iter 11770 || Loss: 2.9703 ||timer: 0.0770 sec.\n",
      "iter 11780 || Loss: 3.1501 ||timer: 0.0803 sec.\n",
      "iter 11790 || Loss: 1.1881 ||timer: 0.0783 sec.\n",
      "iter 11800 || Loss: 2.4715 ||timer: 0.0768 sec.\n",
      "iter 11810 || Loss: 2.4596 ||timer: 0.0759 sec.\n",
      "iter 11820 || Loss: 2.4036 ||timer: 0.0784 sec.\n",
      "iter 11830 || Loss: 4.0046 ||timer: 0.0782 sec.\n",
      "iter 11840 || Loss: 2.6084 ||timer: 0.0776 sec.\n",
      "iter 11850 || Loss: 2.4125 ||timer: 0.0786 sec.\n",
      "iter 11860 || Loss: 2.7551 ||timer: 0.0796 sec.\n",
      "iter 11870 || Loss: 1.6736 ||timer: 0.0785 sec.\n",
      "iter 11880 || Loss: 1.1460 ||timer: 0.0760 sec.\n",
      "iter 11890 || Loss: 1.8600 ||timer: 0.0778 sec.\n",
      "iter 11900 || Loss: 3.4159 ||timer: 0.0769 sec.\n",
      "iter 11910 || Loss: 2.2910 ||timer: 0.0762 sec.\n",
      "iter 11920 || Loss: 2.1145 ||timer: 0.0783 sec.\n",
      "iter 11930 || Loss: 2.0361 ||timer: 0.0770 sec.\n",
      "iter 11940 || Loss: 2.1480 ||timer: 0.0805 sec.\n",
      "iter 11950 || Loss: 2.8459 ||timer: 0.0770 sec.\n",
      "iter 11960 || Loss: 3.3879 ||timer: 0.0805 sec.\n",
      "iter 11970 || Loss: 6.2219 ||timer: 0.0774 sec.\n",
      "iter 11980 || Loss: 1.8852 ||timer: 0.0901 sec.\n",
      "iter 11990 || Loss: 4.1105 ||Change learning rate to:  1.0000000000000002e-06\n",
      "timer: 0.0760 sec.\n",
      "iter 12000 || Loss: 3.2479 ||Saving state, iter: 12000\n",
      "timer: 0.0863 sec.\n",
      "iter 12010 || Loss: 3.4324 ||timer: 0.0827 sec.\n",
      "iter 12020 || Loss: 1.5469 ||timer: 0.0800 sec.\n",
      "iter 12030 || Loss: 1.7912 ||timer: 0.0825 sec.\n",
      "iter 12040 || Loss: 1.3529 ||timer: 0.0801 sec.\n",
      "iter 12050 || Loss: 2.4109 ||timer: 0.0752 sec.\n",
      "iter 12060 || Loss: 7.1433 ||timer: 0.0775 sec.\n",
      "iter 12070 || Loss: 6.9273 ||timer: 0.0805 sec.\n",
      "iter 12080 || Loss: 1.2160 ||timer: 0.0763 sec.\n",
      "iter 12090 || Loss: 3.1461 ||timer: 0.0776 sec.\n",
      "iter 12100 || Loss: 4.3892 ||timer: 0.0798 sec.\n",
      "iter 12110 || Loss: 2.3150 ||timer: 0.0767 sec.\n",
      "iter 12120 || Loss: 2.3794 ||timer: 0.0808 sec.\n",
      "iter 12130 || Loss: 5.0650 ||timer: 0.0802 sec.\n",
      "iter 12140 || Loss: 1.8120 ||timer: 0.0790 sec.\n",
      "iter 12150 || Loss: 2.1517 ||timer: 0.0799 sec.\n",
      "iter 12160 || Loss: 1.8558 ||timer: 0.0767 sec.\n",
      "iter 12170 || Loss: 2.6229 ||timer: 0.0780 sec.\n",
      "iter 12180 || Loss: 2.2960 ||timer: 0.0781 sec.\n",
      "iter 12190 || Loss: 4.3822 ||timer: 0.0804 sec.\n",
      "iter 12200 || Loss: 2.0682 ||timer: 0.0761 sec.\n",
      "iter 12210 || Loss: 2.1356 ||timer: 0.0806 sec.\n",
      "iter 12220 || Loss: 1.8676 ||timer: 0.0761 sec.\n",
      "iter 12230 || Loss: 0.9823 ||timer: 0.0783 sec.\n",
      "iter 12240 || Loss: 1.3700 ||timer: 0.0775 sec.\n",
      "iter 12250 || Loss: 2.8082 ||timer: 0.0792 sec.\n",
      "iter 12260 || Loss: 3.2287 ||timer: 0.0805 sec.\n",
      "iter 12270 || Loss: 2.9010 ||timer: 0.0783 sec.\n",
      "iter 12280 || Loss: 2.1289 ||timer: 0.0773 sec.\n",
      "iter 12290 || Loss: 1.9356 ||timer: 0.0800 sec.\n",
      "iter 12300 || Loss: 3.7678 ||timer: 0.0780 sec.\n",
      "iter 12310 || Loss: 3.2496 ||timer: 0.0782 sec.\n",
      "iter 12320 || Loss: 1.2403 ||timer: 0.0782 sec.\n",
      "iter 12330 || Loss: 6.5778 ||timer: 0.0800 sec.\n",
      "iter 12340 || Loss: 2.7029 ||timer: 0.0780 sec.\n",
      "iter 12350 || Loss: 1.9049 ||timer: 0.0782 sec.\n",
      "iter 12360 || Loss: 3.4081 ||timer: 0.0785 sec.\n",
      "iter 12370 || Loss: 1.3974 ||timer: 0.0797 sec.\n",
      "iter 12380 || Loss: 3.1221 ||timer: 0.0801 sec.\n",
      "iter 12390 || Loss: 4.3305 ||timer: 0.0765 sec.\n",
      "iter 12400 || Loss: 2.2579 ||timer: 0.0769 sec.\n",
      "iter 12410 || Loss: 1.8103 ||timer: 0.0794 sec.\n",
      "iter 12420 || Loss: 5.6856 ||timer: 0.0783 sec.\n",
      "iter 12430 || Loss: 2.4769 ||timer: 0.0775 sec.\n",
      "iter 12440 || Loss: 3.0478 ||timer: 0.0783 sec.\n",
      "iter 12450 || Loss: 1.6583 ||timer: 0.0795 sec.\n",
      "iter 12460 || Loss: 1.8386 ||timer: 0.0769 sec.\n",
      "iter 12470 || Loss: 1.5362 ||timer: 0.0793 sec.\n",
      "iter 12480 || Loss: 3.8452 ||timer: 0.0789 sec.\n",
      "iter 12490 || Loss: 2.9201 ||timer: 0.0785 sec.\n",
      "iter 12500 || Loss: 3.6586 ||Saving state, iter: 12500\n",
      "timer: 0.0804 sec.\n",
      "iter 12510 || Loss: 2.3789 ||timer: 0.0785 sec.\n",
      "iter 12520 || Loss: 1.7408 ||timer: 0.0796 sec.\n",
      "iter 12530 || Loss: 2.5514 ||timer: 0.0803 sec.\n",
      "iter 12540 || Loss: 5.0389 ||timer: 0.0779 sec.\n",
      "iter 12550 || Loss: 2.0900 ||timer: 0.0768 sec.\n",
      "iter 12560 || Loss: 2.7246 ||timer: 0.0787 sec.\n",
      "iter 12570 || Loss: 2.5072 ||timer: 0.0761 sec.\n",
      "iter 12580 || Loss: 4.6470 ||timer: 0.0775 sec.\n",
      "iter 12590 || Loss: 2.3215 ||timer: 0.0799 sec.\n",
      "iter 12600 || Loss: 3.4010 ||timer: 0.0760 sec.\n",
      "iter 12610 || Loss: 5.4880 ||timer: 0.0782 sec.\n",
      "iter 12620 || Loss: 1.9511 ||timer: 0.0791 sec.\n",
      "iter 12630 || Loss: 1.5288 ||timer: 0.0799 sec.\n",
      "iter 12640 || Loss: 2.8611 ||timer: 0.0770 sec.\n",
      "iter 12650 || Loss: 3.5713 ||timer: 0.0799 sec.\n",
      "iter 12660 || Loss: 3.2456 ||timer: 0.0793 sec.\n",
      "iter 12670 || Loss: 1.6394 ||timer: 0.0806 sec.\n",
      "iter 12680 || Loss: 2.7934 ||timer: 0.0763 sec.\n",
      "iter 12690 || Loss: 3.8862 ||timer: 0.0800 sec.\n",
      "iter 12700 || Loss: 1.1219 ||timer: 0.0792 sec.\n",
      "iter 12710 || Loss: 1.3839 ||timer: 0.0767 sec.\n",
      "iter 12720 || Loss: 2.8370 ||timer: 0.0805 sec.\n",
      "iter 12730 || Loss: 3.9254 ||timer: 0.0804 sec.\n",
      "iter 12740 || Loss: 3.0805 ||timer: 0.0759 sec.\n",
      "iter 12750 || Loss: 4.3974 ||timer: 0.0771 sec.\n",
      "iter 12760 || Loss: 4.0897 ||timer: 0.0808 sec.\n",
      "iter 12770 || Loss: 1.1475 ||timer: 0.0756 sec.\n",
      "iter 12780 || Loss: 2.3778 ||timer: 0.0776 sec.\n",
      "iter 12790 || Loss: 3.5671 ||timer: 0.0784 sec.\n",
      "iter 12800 || Loss: 3.7148 ||timer: 0.0763 sec.\n",
      "iter 12810 || Loss: 1.9909 ||timer: 0.0807 sec.\n",
      "iter 12820 || Loss: 1.8852 ||timer: 0.0786 sec.\n",
      "iter 12830 || Loss: 2.0992 ||timer: 0.0865 sec.\n",
      "iter 12840 || Loss: 3.3771 ||timer: 0.0792 sec.\n",
      "iter 12850 || Loss: 1.5056 ||timer: 0.0796 sec.\n",
      "iter 12860 || Loss: 3.4808 ||timer: 0.0761 sec.\n",
      "iter 12870 || Loss: 3.2652 ||timer: 0.0770 sec.\n",
      "iter 12880 || Loss: 2.5745 ||timer: 0.0799 sec.\n",
      "iter 12890 || Loss: 1.1815 ||timer: 0.0759 sec.\n",
      "iter 12900 || Loss: 2.6603 ||timer: 0.0780 sec.\n",
      "iter 12910 || Loss: 4.6200 ||timer: 0.0757 sec.\n",
      "iter 12920 || Loss: 1.9874 ||timer: 0.0800 sec.\n",
      "iter 12930 || Loss: 2.2758 ||timer: 0.0767 sec.\n",
      "iter 12940 || Loss: 2.0286 ||timer: 0.0767 sec.\n",
      "iter 12950 || Loss: 2.8240 ||timer: 0.0795 sec.\n",
      "iter 12960 || Loss: 1.9135 ||timer: 0.0809 sec.\n",
      "iter 12970 || Loss: 2.8629 ||timer: 0.0787 sec.\n",
      "iter 12980 || Loss: 1.5428 ||timer: 0.0804 sec.\n",
      "iter 12990 || Loss: 2.3603 ||timer: 0.0791 sec.\n",
      "iter 13000 || Loss: 4.8076 ||Saving state, iter: 13000\n",
      "timer: 0.0802 sec.\n",
      "iter 13010 || Loss: 3.0036 ||timer: 0.0805 sec.\n",
      "iter 13020 || Loss: 5.1567 ||timer: 0.0775 sec.\n",
      "iter 13030 || Loss: 3.9092 ||timer: 0.0760 sec.\n",
      "iter 13040 || Loss: 2.0143 ||timer: 0.0800 sec.\n",
      "iter 13050 || Loss: 1.7353 ||timer: 0.0780 sec.\n",
      "iter 13060 || Loss: 3.3325 ||timer: 0.0756 sec.\n",
      "iter 13070 || Loss: 1.8254 ||timer: 0.0768 sec.\n",
      "iter 13080 || Loss: 1.7105 ||timer: 0.0770 sec.\n",
      "iter 13090 || Loss: 3.8230 ||timer: 0.0778 sec.\n",
      "iter 13100 || Loss: 1.6174 ||timer: 0.0762 sec.\n",
      "iter 13110 || Loss: 2.3128 ||timer: 0.0798 sec.\n",
      "iter 13120 || Loss: 5.0919 ||timer: 0.0804 sec.\n",
      "iter 13130 || Loss: 1.9134 ||timer: 0.0774 sec.\n",
      "iter 13140 || Loss: 4.1168 ||timer: 0.0780 sec.\n",
      "iter 13150 || Loss: 1.4387 ||timer: 0.0796 sec.\n",
      "iter 13160 || Loss: 5.0977 ||timer: 0.0773 sec.\n",
      "iter 13170 || Loss: 2.9027 ||timer: 0.0784 sec.\n",
      "iter 13180 || Loss: 2.6068 ||timer: 0.0773 sec.\n",
      "iter 13190 || Loss: 3.8294 ||timer: 0.0804 sec.\n",
      "iter 13200 || Loss: 1.2464 ||timer: 0.0761 sec.\n",
      "iter 13210 || Loss: 6.1048 ||timer: 0.0791 sec.\n",
      "iter 13220 || Loss: 1.3043 ||timer: 0.0868 sec.\n",
      "iter 13230 || Loss: 1.3457 ||timer: 0.0779 sec.\n",
      "iter 13240 || Loss: 4.4050 ||timer: 0.0798 sec.\n",
      "iter 13250 || Loss: 1.0909 ||timer: 0.0796 sec.\n",
      "iter 13260 || Loss: 1.7301 ||timer: 0.0770 sec.\n",
      "iter 13270 || Loss: 1.6867 ||timer: 0.0768 sec.\n",
      "iter 13280 || Loss: 1.5655 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0757 sec.\n",
      "iter 13290 || Loss: 3.9264 ||timer: 0.0757 sec.\n",
      "iter 13300 || Loss: 3.7026 ||timer: 0.0766 sec.\n",
      "iter 13310 || Loss: 2.0460 ||timer: 0.0775 sec.\n",
      "iter 13320 || Loss: 3.5959 ||timer: 0.0792 sec.\n",
      "iter 13330 || Loss: 1.7089 ||timer: 0.0763 sec.\n",
      "iter 13340 || Loss: 2.0348 ||timer: 0.0815 sec.\n",
      "iter 13350 || Loss: 2.4017 ||timer: 0.0774 sec.\n",
      "iter 13360 || Loss: 2.7156 ||timer: 0.0764 sec.\n",
      "iter 13370 || Loss: 2.6018 ||timer: 0.0784 sec.\n",
      "iter 13380 || Loss: 2.0541 ||timer: 0.0777 sec.\n",
      "iter 13390 || Loss: 2.0404 ||timer: 0.0768 sec.\n",
      "iter 13400 || Loss: 2.6768 ||timer: 0.0808 sec.\n",
      "iter 13410 || Loss: 2.1300 ||timer: 0.0788 sec.\n",
      "iter 13420 || Loss: 4.4706 ||timer: 0.0765 sec.\n",
      "iter 13430 || Loss: 3.0868 ||timer: 0.0793 sec.\n",
      "iter 13440 || Loss: 3.3256 ||timer: 0.0804 sec.\n",
      "iter 13450 || Loss: 1.9871 ||timer: 0.0813 sec.\n",
      "iter 13460 || Loss: 1.9917 ||timer: 0.0819 sec.\n",
      "iter 13470 || Loss: 1.6248 ||timer: 0.0802 sec.\n",
      "iter 13480 || Loss: 3.6341 ||timer: 0.0762 sec.\n",
      "iter 13490 || Loss: 3.2172 ||timer: 0.0773 sec.\n",
      "iter 13500 || Loss: 1.5409 ||Saving state, iter: 13500\n",
      "timer: 0.0783 sec.\n",
      "iter 13510 || Loss: 2.0455 ||timer: 0.0801 sec.\n",
      "iter 13520 || Loss: 1.4189 ||timer: 0.0772 sec.\n",
      "iter 13530 || Loss: 1.9774 ||timer: 0.0770 sec.\n",
      "iter 13540 || Loss: 3.1329 ||timer: 0.0759 sec.\n",
      "iter 13550 || Loss: 1.5118 ||timer: 0.0773 sec.\n",
      "iter 13560 || Loss: 1.8436 ||timer: 0.0782 sec.\n",
      "iter 13570 || Loss: 1.5192 ||timer: 0.0798 sec.\n",
      "iter 13580 || Loss: 3.0592 ||timer: 0.0793 sec.\n",
      "iter 13590 || Loss: 3.1876 ||timer: 0.0799 sec.\n",
      "iter 13600 || Loss: 4.4527 ||timer: 0.0767 sec.\n",
      "iter 13610 || Loss: 1.3360 ||timer: 0.0803 sec.\n",
      "iter 13620 || Loss: 1.9638 ||timer: 0.0774 sec.\n",
      "iter 13630 || Loss: 2.8375 ||timer: 0.0777 sec.\n",
      "iter 13640 || Loss: 0.8300 ||timer: 0.0775 sec.\n",
      "iter 13650 || Loss: 2.3472 ||timer: 0.0794 sec.\n",
      "iter 13660 || Loss: 2.0133 ||timer: 0.0784 sec.\n",
      "iter 13670 || Loss: 2.4828 ||timer: 0.0796 sec.\n",
      "iter 13680 || Loss: 1.1112 ||timer: 0.0783 sec.\n",
      "iter 13690 || Loss: 1.2453 ||timer: 0.0801 sec.\n",
      "iter 13700 || Loss: 2.1953 ||timer: 0.0781 sec.\n",
      "iter 13710 || Loss: 2.8614 ||timer: 0.0784 sec.\n",
      "iter 13720 || Loss: 1.6598 ||timer: 0.0817 sec.\n",
      "iter 13730 || Loss: 1.6092 ||timer: 0.0770 sec.\n",
      "iter 13740 || Loss: 1.9869 ||timer: 0.0758 sec.\n",
      "iter 13750 || Loss: 1.9579 ||timer: 0.0783 sec.\n",
      "iter 13760 || Loss: 2.7563 ||timer: 0.0785 sec.\n",
      "iter 13770 || Loss: 3.2658 ||timer: 0.0766 sec.\n",
      "iter 13780 || Loss: 2.8382 ||timer: 0.0808 sec.\n",
      "iter 13790 || Loss: 2.0653 ||timer: 0.0780 sec.\n",
      "iter 13800 || Loss: 7.3397 ||timer: 0.0766 sec.\n",
      "iter 13810 || Loss: 4.0235 ||timer: 0.0805 sec.\n",
      "iter 13820 || Loss: 3.1501 ||timer: 0.0796 sec.\n",
      "iter 13830 || Loss: 1.9046 ||timer: 0.0778 sec.\n",
      "iter 13840 || Loss: 2.7786 ||timer: 0.0764 sec.\n",
      "iter 13850 || Loss: 2.5306 ||timer: 0.0800 sec.\n",
      "iter 13860 || Loss: 4.1955 ||timer: 0.0769 sec.\n",
      "iter 13870 || Loss: 2.6796 ||timer: 0.0776 sec.\n",
      "iter 13880 || Loss: 0.7710 ||timer: 0.0774 sec.\n",
      "iter 13890 || Loss: 3.2659 ||timer: 0.0786 sec.\n",
      "iter 13900 || Loss: 1.2711 ||timer: 0.0779 sec.\n",
      "iter 13910 || Loss: 3.4411 ||timer: 0.0799 sec.\n",
      "iter 13920 || Loss: 1.8976 ||timer: 0.0803 sec.\n",
      "iter 13930 || Loss: 2.7637 ||timer: 0.0779 sec.\n",
      "iter 13940 || Loss: 3.2120 ||timer: 0.0761 sec.\n",
      "iter 13950 || Loss: 1.0331 ||timer: 0.0776 sec.\n",
      "iter 13960 || Loss: 2.1782 ||timer: 0.0778 sec.\n",
      "iter 13970 || Loss: 7.1733 ||timer: 0.0763 sec.\n",
      "iter 13980 || Loss: 4.2881 ||timer: 0.0803 sec.\n",
      "iter 13990 || Loss: 1.1802 ||timer: 0.0799 sec.\n",
      "iter 14000 || Loss: 4.0881 ||Saving state, iter: 14000\n",
      "timer: 0.0779 sec.\n",
      "iter 14010 || Loss: 3.3065 ||timer: 0.0759 sec.\n",
      "iter 14020 || Loss: 4.0685 ||timer: 0.0797 sec.\n",
      "iter 14030 || Loss: 1.0697 ||timer: 0.0768 sec.\n",
      "iter 14040 || Loss: 2.3409 ||timer: 0.0796 sec.\n",
      "iter 14050 || Loss: 1.8855 ||timer: 0.0762 sec.\n",
      "iter 14060 || Loss: 3.6255 ||timer: 0.0785 sec.\n",
      "iter 14070 || Loss: 3.7717 ||timer: 0.0769 sec.\n",
      "iter 14080 || Loss: 3.8422 ||timer: 0.0800 sec.\n",
      "iter 14090 || Loss: 1.8057 ||timer: 0.0804 sec.\n",
      "iter 14100 || Loss: 1.6135 ||timer: 0.0766 sec.\n",
      "iter 14110 || Loss: 1.3789 ||timer: 0.0758 sec.\n",
      "iter 14120 || Loss: 3.7382 ||timer: 0.0789 sec.\n",
      "iter 14130 || Loss: 3.5012 ||timer: 0.0789 sec.\n",
      "iter 14140 || Loss: 1.8476 ||timer: 0.0770 sec.\n",
      "iter 14150 || Loss: 3.0931 ||timer: 0.0783 sec.\n",
      "iter 14160 || Loss: 3.5630 ||timer: 0.0775 sec.\n",
      "iter 14170 || Loss: 2.7704 ||timer: 0.0798 sec.\n",
      "iter 14180 || Loss: 3.4019 ||timer: 0.0754 sec.\n",
      "iter 14190 || Loss: 1.6729 ||timer: 0.0762 sec.\n",
      "iter 14200 || Loss: 2.9911 ||timer: 0.0786 sec.\n",
      "iter 14210 || Loss: 1.5977 ||timer: 0.0807 sec.\n",
      "iter 14220 || Loss: 1.7694 ||timer: 0.0802 sec.\n",
      "iter 14230 || Loss: 1.2897 ||timer: 0.0795 sec.\n",
      "iter 14240 || Loss: 2.2327 ||timer: 0.0777 sec.\n",
      "iter 14250 || Loss: 1.9216 ||timer: 0.0778 sec.\n",
      "iter 14260 || Loss: 5.5661 ||timer: 0.0791 sec.\n",
      "iter 14270 || Loss: 1.3464 ||timer: 0.0796 sec.\n",
      "iter 14280 || Loss: 1.7510 ||timer: 0.0757 sec.\n",
      "iter 14290 || Loss: 1.3529 ||timer: 0.0776 sec.\n",
      "iter 14300 || Loss: 2.0530 ||timer: 0.0794 sec.\n",
      "iter 14310 || Loss: 4.1289 ||timer: 0.0771 sec.\n",
      "iter 14320 || Loss: 3.4886 ||timer: 0.0778 sec.\n",
      "iter 14330 || Loss: 3.7654 ||timer: 0.0769 sec.\n",
      "iter 14340 || Loss: 1.6931 ||timer: 0.0801 sec.\n",
      "iter 14350 || Loss: 1.4771 ||timer: 0.0777 sec.\n",
      "iter 14360 || Loss: 2.3588 ||timer: 0.0769 sec.\n",
      "iter 14370 || Loss: 1.7477 ||timer: 0.0804 sec.\n",
      "iter 14380 || Loss: 1.9520 ||timer: 0.0780 sec.\n",
      "iter 14390 || Loss: 2.2588 ||timer: 0.0782 sec.\n",
      "iter 14400 || Loss: 3.0224 ||timer: 0.0799 sec.\n",
      "iter 14410 || Loss: 2.7001 ||timer: 0.0805 sec.\n",
      "iter 14420 || Loss: 2.8007 ||timer: 0.0793 sec.\n",
      "iter 14430 || Loss: 2.4252 ||timer: 0.0777 sec.\n",
      "iter 14440 || Loss: 3.7019 ||timer: 0.0801 sec.\n",
      "iter 14450 || Loss: 1.6539 ||timer: 0.0787 sec.\n",
      "iter 14460 || Loss: 2.8644 ||timer: 0.0774 sec.\n",
      "iter 14470 || Loss: 1.8944 ||timer: 0.0784 sec.\n",
      "iter 14480 || Loss: 1.3070 ||timer: 0.0814 sec.\n",
      "iter 14490 || Loss: 2.5988 ||timer: 0.0795 sec.\n",
      "iter 14500 || Loss: 4.3796 ||Saving state, iter: 14500\n",
      "timer: 0.0780 sec.\n",
      "iter 14510 || Loss: 4.2764 ||timer: 0.0764 sec.\n",
      "iter 14520 || Loss: 2.1771 ||timer: 0.0800 sec.\n",
      "iter 14530 || Loss: 1.1874 ||timer: 0.0806 sec.\n",
      "iter 14540 || Loss: 2.1408 ||timer: 0.0766 sec.\n",
      "iter 14550 || Loss: 2.3152 ||timer: 0.0788 sec.\n",
      "iter 14560 || Loss: 1.5533 ||timer: 0.0798 sec.\n",
      "iter 14570 || Loss: 2.8368 ||timer: 0.0782 sec.\n",
      "iter 14580 || Loss: 2.3479 ||timer: 0.0761 sec.\n",
      "iter 14590 || Loss: 1.5704 ||timer: 0.0774 sec.\n",
      "iter 14600 || Loss: 1.8368 ||timer: 0.0763 sec.\n",
      "iter 14610 || Loss: 1.4172 ||timer: 0.0777 sec.\n",
      "iter 14620 || Loss: 3.8172 ||timer: 0.0807 sec.\n",
      "iter 14630 || Loss: 3.0850 ||timer: 0.0802 sec.\n",
      "iter 14640 || Loss: 1.7377 ||timer: 0.0804 sec.\n",
      "iter 14650 || Loss: 2.9015 ||timer: 0.0800 sec.\n",
      "iter 14660 || Loss: 2.2007 ||timer: 0.0871 sec.\n",
      "iter 14670 || Loss: 1.6984 ||timer: 0.0786 sec.\n",
      "iter 14680 || Loss: 3.0309 ||timer: 0.0773 sec.\n",
      "iter 14690 || Loss: 5.2559 ||timer: 0.0803 sec.\n",
      "iter 14700 || Loss: 4.0674 ||timer: 0.0764 sec.\n",
      "iter 14710 || Loss: 3.6366 ||timer: 0.0890 sec.\n",
      "iter 14720 || Loss: 1.5323 ||timer: 0.0776 sec.\n",
      "iter 14730 || Loss: 1.1566 ||timer: 0.0798 sec.\n",
      "iter 14740 || Loss: 1.7221 ||timer: 0.0761 sec.\n",
      "iter 14750 || Loss: 1.5059 ||timer: 0.0759 sec.\n",
      "iter 14760 || Loss: 1.7556 ||timer: 0.0801 sec.\n",
      "iter 14770 || Loss: 2.3483 ||timer: 0.0765 sec.\n",
      "iter 14780 || Loss: 7.0206 ||timer: 0.0795 sec.\n",
      "iter 14790 || Loss: 1.6776 ||timer: 0.0759 sec.\n",
      "iter 14800 || Loss: 2.5238 ||timer: 0.0787 sec.\n",
      "iter 14810 || Loss: 3.3457 ||timer: 0.0758 sec.\n",
      "iter 14820 || Loss: 2.6957 ||timer: 0.0802 sec.\n",
      "iter 14830 || Loss: 2.1698 ||timer: 0.0758 sec.\n",
      "iter 14840 || Loss: 2.6083 ||timer: 0.0781 sec.\n",
      "iter 14850 || Loss: 3.5888 ||timer: 0.0764 sec.\n",
      "iter 14860 || Loss: 3.2216 ||timer: 0.0780 sec.\n",
      "iter 14870 || Loss: 1.4727 ||timer: 0.0766 sec.\n",
      "iter 14880 || Loss: 8.7630 ||timer: 0.0803 sec.\n",
      "iter 14890 || Loss: 1.4854 ||timer: 0.0774 sec.\n",
      "iter 14900 || Loss: 5.7495 ||timer: 0.0775 sec.\n",
      "iter 14910 || Loss: 2.3813 ||timer: 0.0763 sec.\n",
      "iter 14920 || Loss: 1.7674 ||timer: 0.0764 sec.\n",
      "iter 14930 || Loss: 1.3092 ||timer: 0.0750 sec.\n",
      "iter 14940 || Loss: 2.0650 ||"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/austin/SSD-SubT/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.0772 sec.\n",
      "iter 14950 || Loss: 4.5401 ||timer: 0.0786 sec.\n",
      "iter 14960 || Loss: 2.0144 ||timer: 0.0801 sec.\n",
      "iter 14970 || Loss: 1.9941 ||timer: 0.0758 sec.\n",
      "iter 14980 || Loss: 4.9978 ||timer: 0.0788 sec.\n",
      "iter 14990 || Loss: 5.1595 ||"
     ]
    }
   ],
   "source": [
    "step_index = 0\n",
    "for iteration in range(START_ITER, cfg['max_iter']):\n",
    "    if iteration in cfg['lr_steps']:\n",
    "        step_index += 1\n",
    "        adjust_learning_rate(optimizer, GAMMA, step_index)\n",
    "    \n",
    "    # make sure data iter not out of range\n",
    "    try:\n",
    "        images, targets = next(batch_iterator)\n",
    "        #print(targets[0][0][4].item(), label[int(targets[0][0][4].item())])\n",
    "    except StopIteration:\n",
    "        batch_iterator = iter(data_loader)\n",
    "        images, targets = next(batch_iterator)\n",
    "    if CUDA:\n",
    "        images = Variable(images.cuda())\n",
    "        targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n",
    "    else:\n",
    "        images = Variable(images)\n",
    "        targets = [Variable(ann, volatile=True) for ann in targets]\n",
    "    \n",
    "    # Forward\n",
    "    t0 = time.time()\n",
    "    out = net(images)\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss_l, loss_c = criterion(out, targets)\n",
    "    loss = loss_l + loss_c\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    t1 = time.time()\n",
    "    loc_loss += loss_l.item()\n",
    "    conf_loss += loss_c.item()\n",
    "    \n",
    "    if iteration % 10 == 0:\n",
    "            print('timer: %.4f sec.' % (t1 - t0))\n",
    "            print('iter ' + repr(PRETRAINED_ITER + iteration) + ' || Loss: %.4f ||' % (loss.item()), end='')\n",
    "    \n",
    "    if iteration != 0 and iteration % SAVE_MODEL_ITER == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), SAVE_FOLDER + DATASET_NAME + \"_\" +\n",
    "                       repr(PRETRAINED_ITER + iteration) + '.pth')\n",
    "# Save final model\n",
    "torch.save(ssd_net.state_dict(),\n",
    "            SAVE_FOLDER + DATASET_NAME + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
